# 7、功能实现详解

<details>
<summary>相关源文件</summary>
internal/handler/document_handler.go
internal/service/document_service.go
internal/service/parser_service.go
internal/service/search_service.go
internal/service/embedding_service.go
internal/middleware/auth.go
internal/service/user_service.go
python-parser-service/service/server.py
python-parser-service/service/pdf_parser.py
python-parser-service/service/docx_parser.py
</details>

## 概述

本文档深入分析LAST-doc系统的9个核心功能的技术实现细节，涵盖文档上传、文档解析、语义检索、用户认证、API密钥管理、版本管理、标签系统、分类管理和备份恢复等功能。通过详细的代码分析和技术解构，揭示每个功能的设计思路、实现机制和优化策略。

## feature-document-upload (文档上传功能)

### 设计理念

文档上传功能是系统的核心入口，负责接收用户上传的文档文件，并进行完整的生命周期管理。该功能采用分层架构设计，实现了从HTTP请求处理到文件存储的完整流程，确保数据完整性、安全性和可追溯性。

### 实现深度剖析

#### HTTP请求处理层

[`DocumentHandler.UploadDocument()`](internal/handler/document_handler.go:29) 方法实现了文档上传的HTTP接口处理：

```go
func (h *DocumentHandler) UploadDocument(c *gin.Context) {
    // 1. 表单数据提取
    name := c.PostForm("name")
    docType := c.PostForm("type")
    category := c.PostForm("category")
    version := c.PostForm("version")
    library := c.PostForm("library")
    description := c.PostForm("description")
    tagsStr := c.PostForm("tags")
    
    // 2. 参数验证
    if name == "" || docType == "" || category == "" || 
       version == "" || library == "" {
        c.JSON(http.StatusBadRequest, gin.H{
            "code": 400,
            "message": "必填参数不能为空",
        })
        return
    }
    
    // 3. 文件获取
    file, err := c.FormFile("file")
    if err != nil {
        c.JSON(http.StatusBadRequest, gin.H{
            "code": 400,
            "message": "获取上传文件失败: " + err.Error(),
        })
        return
    }
    
    // 4. 文件类型验证
    if !isValidFileType(file.Filename, model.DocumentType(docType)) {
        c.JSON(http.StatusBadRequest, gin.H{
            "code": 400,
            "message": "文件类型与文档类型不匹配",
        })
        return
    }
}
```

**关键技术点**：
- 使用Gin框架的表单处理能力，支持multipart/form-data格式
- 分离参数验证和业务逻辑，提高代码可维护性
- 文件类型验证通过扩展名与声明类型的匹配实现

#### 业务逻辑层

[`DocumentService.UploadDocument()`](internal/service/document_service.go:70) 方法实现了文档上传的核心业务逻辑：

```go
func (s *documentService) UploadDocument(ctx context.Context, file *multipart.FileHeader, 
    name, docType, category, version, library, description string, tags []string) (*model.Document, error) {
    
    // 1. 文档类型和分类验证
    documentType := model.DocumentType(docType)
    if !isValidDocumentType(documentType) {
        return nil, fmt.Errorf("invalid document type: %s", docType)
    }
    documentCategory := model.DocumentCategory(category)
    if !isValidDocumentCategory(documentCategory) {
        return nil, fmt.Errorf("invalid document category: %s", category)
    }
    
    // 2. 检查同库文档（实现版本管理）
    existingDocs, _, err := s.documentRepo.List(ctx, 1, 100, map[string]any{
        "library": library,
    })
    
    // 3. 生成文档ID
    var documentID string
    if len(existingDocs) > 0 {
        documentID = existingDocs[0].ID  // 复用现有文档ID
    } else {
        documentID = uuid.New().String()  // 创建新文档ID
    }
    
    // 4. 创建文档存储目录
    storageDir := filepath.Join(s.baseStorageDir, documentID)
    if err := os.MkdirAll(storageDir, 0755); err != nil {
        return nil, fmt.Errorf("failed to create storage directory: %v", err)
    }
    
    // 5. 保存文件到磁盘
    filePath := filepath.Join(storageDir, file.Filename)
    if err := s.saveFile(file, filePath); err != nil {
        return nil, fmt.Errorf("failed to save file: %v", err)
    }
    
    // 6. 创建或更新文档记录
    var document *model.Document
    if len(existingDocs) == 0 {
        document = &model.Document{
            ID:          documentID,
            Name:        name,
            Type:        documentType,
            Category:    documentCategory,
            Version:     version,
            Tags:        tags,
            FilePath:    filePath,
            FileSize:    file.Size,
            Status:      model.DocumentStatusProcessing,
            Description: description,
            Library:     library,
        }
        if err := s.documentRepo.Create(ctx, document); err != nil {
            os.Remove(filePath)  // 清理已保存的文件
            return nil, fmt.Errorf("failed to create document record: %v", err)
        }
    } else {
        document = existingDocs[0]  // 使用现有文档记录
    }
    
    // 7. 版本号唯一性检查
    existingVersion, err := s.versionRepo.GetByDocumentIDAndVersion(ctx, documentID, version)
    if err == nil && existingVersion != nil {
        os.Remove(filePath)
        if len(existingDocs) == 0 {
            s.documentRepo.Delete(ctx, documentID)
        }
        return nil, fmt.Errorf("版本号 %s 已存在，请使用不同的版本号", version)
    }
    
    // 8. 创建文档版本记录
    documentVersion := &model.DocumentVersion{
        ID:          uuid.New().String(),
        DocumentID:  document.ID,
        Version:     version,
        FilePath:    filePath,
        FileSize:    file.Size,
        Status:      model.DocumentStatusProcessing,
        Description: description,
    }
    if err := s.versionRepo.Create(ctx, documentVersion); err != nil {
        os.Remove(filePath)
        if len(existingDocs) == 0 {
            s.documentRepo.Delete(ctx, documentID)
        }
        return nil, fmt.Errorf("failed to create document version record: %v", err)
    }
    
    // 9. 异步处理文档解析
    go s.processDocumentWithFile(documentID, version, filePath)
    
    return document, nil
}
```

### 文档上传流程

```mermaid
sequenceDiagram
    participant Client
    participant Handler
    participant Service
    participant Repository
    participant Storage
    participant Parser
    
    Client->>Handler: POST /api/documents/upload
    Handler->>Handler: 提取表单数据
    Handler->>Handler: 验证参数和文件类型
    Handler->>Service: UploadDocument()
    Service->>Service: 验证文档类型和分类
    Service->>Repository: 检查同库文档
    Repository-->>Service: 返回现有文档列表
    alt 同库文档存在
        Service->>Service: 复用文档ID
    else 同库文档不存在
        Service->>Service: 生成新文档ID
        Service->>Repository: 创建文档记录
    end
    Service->>Storage: 创建存储目录
    Service->>Storage: 保存文件到磁盘
    Service->>Repository: 检查版本号唯一性
    Service->>Repository: 创建版本记录
    Service->>Parser: 异步解析文档
    Service-->>Handler: 返回文档信息
    Handler-->>Client: HTTP 200 OK
```

### 实际使用示例

#### 文档上传示例

**1. 基本上传请求**：
```bash
curl -X POST http://localhost:8080/api/documents/upload \
  -H "Authorization: Bearer YOUR_JWT_TOKEN" \
  -F "name=API文档" \
  -F "type=docx" \
  -F "category=document" \
  -F "version=1.0.0" \
  -F "library=my-library" \
  -F "description=RESTful API接口文档" \
  -F "tags=api,rest,文档" \
  -F "file=@api-docs.docx"
```

**2. 版本管理示例**：
```bash
# 上传同一库的第一个版本
curl -X POST http://localhost:8080/api/documents/upload \
  -F "name=API文档 v1" \
  -F "type=docx" \
  -F "category=document" \
  -F "version=1.0.0" \
  -F "library=my-library" \
  -F "file=@api-docs-v1.docx"

# 上传同一库的第二个版本（复用document_id）
curl -X POST http://localhost:8080/api/documents/upload \
  -F "name=API文档 v2" \
  -F "type=docx" \
  -F "category=document" \
  -F "version=1.1.0" \
  -F "library=my-library" \
  -F "file=@api-docs-v2.docx"
```

**3. 错误处理示例**：

**版本号重复错误**：
```json
{
  "code": 500,
  "message": "上传文档失败: 版本号 1.0.0 已存在，请使用不同的版本号"
}
```

**文件类型不匹配错误**：
```json
{
  "code": 400,
  "message": "文件类型与文档类型不匹配"
}
```

### 技术实现细节

#### 1. 文件存储策略

- **存储目录结构**：采用`{baseStorageDir}/{documentID}/{filename}`的层次结构
- **权限管理**：目录权限设置为`0755`，确保可读可执行
- **原子性操作**：失败时自动清理已保存的文件和数据库记录

#### 2. 版本管理机制

- **版本唯一性**：通过`document_id`和`version`的联合索引确保版本号唯一
- **版本复用**：同库文档复用相同的`document_id`，不同版本创建独立的记录
- **状态跟踪**：每个版本独立维护状态（processing/completed/failed）

#### 3. 异步处理设计

异步处理是文档上传功能的关键性能优化点，通过goroutine实现非阻塞的文档解析流程：

**goroutine生命周期管理**：
```go
// 异步处理文档解析
go s.processDocumentWithFile(documentID, version, filePath)
```

- **并发模型**：每个文档上传启动一个独立的goroutine处理解析任务
- **资源隔离**：goroutine之间相互独立，单个解析失败不影响其他任务
- **内存管理**：通过Go运行时的垃圾回收机制自动管理goroutine内存
- **优雅关闭**：实现context取消机制，支持服务优雅关闭时等待所有goroutine完成

**错误隔离机制**：
- **状态标记**：解析失败时更新版本状态为`DocumentStatusFailed`
- **错误日志**：详细记录解析错误信息，便于后续排查
- **重试策略**：支持配置重试次数，提高解析成功率
- **告警机制**：连续多次解析失败时触发系统告警

**Context超时控制**：
```go
func (s *documentService) processDocumentWithFile(documentID, version, filePath string) {
    ctx, cancel := context.WithTimeout(context.Background(), 10*time.Minute)
    defer cancel()
    
    // 在超时上下文中执行解析
    content, metadata, err := s.parserService.ParseDocument(ctx, filePath, docType)
}
```

- **超时设置**：为解析操作设置合理的超时时间（如10分钟）
- **资源清理**：超时后自动取消解析操作，释放相关资源
- **取消传播**：Context取消信号会传播到所有子goroutine
- **优雅降级**：超时后标记文档状态为失败，不影响系统稳定性

**并发控制策略**：
- **工作池模式**：使用worker pool限制并发解析的goroutine数量，避免系统资源耗尽
- **限流机制**：实现令牌桶或漏桶算法，控制解析请求的速率
- **优先级队列**：支持为重要文档设置更高的解析优先级
- **背压机制**：当解析队列过长时，拒绝新的解析请求或降级处理

#### 4. 数据一致性保障

- **事务性操作**：失败时回滚所有已执行的操作
- **级联删除**：删除文档时自动清理对应的版本记录和搜索索引
- **状态同步**：文档状态与版本状态保持一致

### 性能优化

1. **并发控制**：使用goroutine处理文档解析，提高系统吞吐量
2. **批量操作**：支持同时上传多个文档，通过HTTP并发请求实现
3. **缓存策略**：文档列表查询结果缓存，减少数据库访问
4. **索引优化**：在`library`、`type`、`status`等字段上建立索引

### 安全性考虑

1. **文件类型验证**：严格验证文件扩展名与声明的文档类型匹配
2. **路径安全**：使用filepath.Join防止路径遍历攻击
3. **大小限制**：通过中间件限制上传文件大小
4. **权限控制**：通过认证中间件确保只有授权用户可以上传

## feature-document-parsing (文档解析功能)

### 设计理念

文档解析功能采用多解析器架构设计，支持PDF、DOCX、Markdown、Swagger等多种文档格式。通过gRPC通信机制，实现了Go服务与Python解析服务的解耦，充分发挥Python生态在文档处理方面的优势。

### 架构设计

#### 解析服务架构

```mermaid
graph TB
    A[上传服务] --> B[ParserService]
    B --> C{文档类型}
    C -->|Markdown| D[MarkdownParser]
    C -->|Swagger| E[SwaggerParser]
    C -->|OpenAPI| F[OpenAPIParser]
    C -->|JavaDoc| G[JavaDocParser]
    C -->|PDF| H{gRPC连接}
    C -->|DOCX| I{gRPC连接}
    H -->|成功| J[PDFGRPCParser]
    H -->|失败| K[PythonPDFParser]
    I -->|成功| L[DOCXGRPCParser]
    I -->|失败|M[PythonDOCXParser]
    J --> N[Python解析服务]
    K --> N
    L --> N
    M --> N
    N --> O[返回内容和元数据]
```

### 实现深度剖析

#### 解析服务注册

[`ParserService`](internal/service/parser_service.go:26) 采用策略模式，实现了解析器的动态注册和选择：

```go
type parserService struct {
    parsers    map[model.DocumentType]DocumentParser
    grpcClient *GRPCClient
}

func NewParserService() DocumentParserService {
    service := &parserService{
        parsers:    make(map[model.DocumentType]DocumentParser),
        grpcClient: NewGRPCClient(),
    }
    
    // 注册本地解析器
    service.RegisterParser(model.DocumentTypeMarkdown, NewMarkdownParser())
    service.RegisterParser(model.DocumentTypeSwagger, NewSwaggerParser())
    service.RegisterParser(model.DocumentTypeOpenAPI, NewOpenAPIParser())
    service.RegisterParser(model.DocumentTypeJavaDoc, NewJavaDocParser())
    
    // 从环境变量获取gRPC服务器地址
    grpcHost := os.Getenv("GRPC_SERVER_HOST")
    grpcPort := os.Getenv("GRPC_SERVER_PORT")
    grpcAddr := grpcHost + ":" + grpcPort
    
    // 连接到gRPC服务
    if err := service.grpcClient.Connect(grpcAddr); err != nil {
        fmt.Printf("警告：连接gRPC服务失败，将使用本地解析器: %v\n", err)
        // 回退到本地解析器
        service.RegisterParser(model.DocumentTypePDF, NewPDFParser())
        service.RegisterParser(model.DocumentTypeDocx, NewDocxParser())
    } else {
        // 使用gRPC解析器
        service.RegisterParser(model.DocumentTypePDF, NewPDFGRPCParser(service.grpcClient))
        service.RegisterParser(model.DocumentTypeDocx, NewDocxGRPCParser(service.grpcClient))
    }
    
    return service
}
```

**设计优势**：
- **灵活降级**：gRPC服务不可用时自动降级到本地解析器
- **环境配置**：通过环境变量灵活控制解析服务地址
- **扩展性强**：新增文档类型只需注册新的解析器

#### PDF解析实现

Python端的PDF解析服务使用PyPDF2和pdfplumber库实现：

```python
class PDFParser:
    """PDF文档解析器"""
    
    def parse(self, file_path: str) -> Tuple[str, Dict[str, Any]]:
        try:
            self.logger.info(f"开始解析PDF文档: {file_path}")
            
            # 1. 文件存在性检查
            if not os.path.exists(file_path):
                raise FileNotFoundError(f"PDF文件不存在: {file_path}")
            
            file_size = os.path.getsize(file_path)
            self.logger.info(f"PDF文件大小: {file_size} 字节")
            
            # 2. 使用PyPDF2提取文本
            content_text = ""
            page_count = 0
            
            with open(file_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                page_count = len(pdf_reader.pages)
                
                for page_num, page in enumerate(pdf_reader.pages):
                    try:
                        page_text = page.extract_text()
                        # UTF-8编码验证和清理
                        try:
                            page_text.encode('utf-8').decode('utf-8')
                            content_text += page_text + "\n"
                        except UnicodeError as e:
                            clean_text = page_text.encode('utf-8', 
                                errors='replace').decode('utf-8', errors='replace')
                            content_text += clean_text + "\n"
                    except Exception as e:
                        self.logger.warning(f"解析第 {page_num + 1} 页时出错: {e}")
                        continue
            
            # 3. 使用pdfplumber提取元数据
            metadata = self._extract_metadata_with_pdfplumber(file_path)
            
            # 4. 添加基本元数据
            metadata.update({
                'file_size': str(file_size),
                'page_count': str(page_count),
                'content_length': str(len(content_text)),
                'parser': 'PyPDF2 + pdfplumber'
            })
            
            return content_text, metadata
            
        except Exception as e:
            self.logger.error(f"解析PDF文档时发生错误: {e}")
            raise
```

**技术要点**：
- **多层次解析**：PyPDF2提取文本内容，pdfplumber提取元数据
- **错误处理**：单页解析失败不影响整体流程
- **编码处理**：自动检测和清理非UTF-8字符
- **元数据丰富**：提取标题、作者、表格数量、图片数量等信息

#### DOCX解析实现

DOCX解析使用python-docx库，能够完整提取文档结构：

```python
class DOCXParser:
    """DOCX文档解析器"""
    
    def parse(self, file_path: str) -> Tuple[str, Dict[str, Any]]:
        try:
            self.logger.info(f"开始解析DOCX文档: {file_path}")
            
            # 1. 加载文档
            doc = Document(file_path)
            
            # 2. 提取文本内容
            content_text = self._extract_text_content(doc)
            
            # 3. 提取元数据
            metadata = self._extract_metadata(doc, file_path, file_size)
            
            return content_text, metadata
            
        except Exception as e:
            self.logger.error(f"解析DOCX文档时发生错误: {e}")
            raise
    
    def _extract_text_content(self, doc: Document) -> str:
        """提取文档文本内容"""
        content_parts = []
        
        # 提取段落文本
        for paragraph in doc.paragraphs:
            if paragraph.text.strip():
                content_parts.append(paragraph.text)
        
        # 提取表格文本
        for table in doc.tables:
            table_text = self._extract_table_text(table)
            if table_text:
                content_parts.append(f"[表格 {i + 1}]\n{table_text}")
        
        # 提取页眉页脚
        for section in doc.sections:
            for header in section.header.paragraphs:
                if header.text.strip():
                    content_parts.append(f"[页眉] {header.text}")
            for footer in section.footer.paragraphs:
                if footer.text.strip():
                    content_parts.append(f"[页脚] {footer.text}")
        
        return "\n".join(content_parts)
```

**解析能力**：
- **段落提取**：保留文档段落结构
- **表格处理**：解析表格内容并标记
- **页眉页脚**：提取页眉页脚信息
- **超链接统计**：统计文档中的超链接数量

#### gRPC服务实现

[`DocumentParserServicer`](python-parser-service/service/server.py:49) 实现了gRPC服务接口：

```python
class DocumentParserServicer(pb2_grpc.DocumentParserServiceServicer):
    """文档解析服务实现"""
    
    def __init__(self):
        self.pdf_parser = PDFParser()
        self.docx_parser = DOCXParser()
        logger.info("文档解析服务初始化完成")
    
    def ParsePDF(self, request: pb2.ParsePDFRequest, 
                 context: grpc.ServicerContext) -> pb2.ParseDocumentResponse:
        """解析PDF文档"""
        try:
            # 1. 参数验证
            if not request.file_path:
                return pb2.ParseDocumentResponse(
                    success=False,
                    error_message="文件路径不能为空"
                )
            
            # 2. 文件存在性检查
            if not os.path.exists(request.file_path):
                return pb2.ParseDocumentResponse(
                    success=False,
                    error_message=f"文件不存在: {request.file_path}"
                )
            
            # 3. 调用解析器
            content, metadata = self.pdf_parser.parse(request.file_path)
            
            # 4. 转换元数据为gRPC格式
            metadata_map = {str(k): str(v) for k, v in metadata.items()}
            
            return pb2.ParseDocumentResponse(
                success=True,
                content=content,
                metadata=metadata_map
            )
            
        except Exception as e:
            logger.error(f"PDF解析失败: {str(e)}")
            return pb2.ParseDocumentResponse(
                success=False,
                error_message=f"PDF解析失败: {str(e)}"
            )
```

**服务特性**：
- **类型安全**：使用Protocol Buffers定义接口
- **错误处理**：详细的错误信息和日志记录
- **性能优化**：支持并发处理多个解析请求
- **健康检查**：提供服务健康状态检查接口

### 文档解析流程

```mermaid
sequenceDiagram
    participant DocumentService
    participant ParserService
    participant GRPCClient
    participant PythonServer
    participant PDFParser
    participant DOCXParser
    
    DocumentService->>ParserService: ParseDocument(filePath, docType)
    ParserService->>ParserService: 根据类型选择解析器
    alt PDF文档且gRPC连接成功
        ParserService->>GRPCClient: ParsePDF(filePath)
        GRPCClient->>PythonServer: gRPC请求
        PythonServer->>PDFParser: parse(filePath)
        PDFParser->>PDFParser: 读取文件
        PDFParser->>PDFParser: PyPDF2提取文本
        PDFParser->>PDFParser: pdfplumber提取元数据
        PDFParser-->>PythonServer: content, metadata
        PythonServer-->>GRPCClient: ParseDocumentResponse
        GRPCClient-->>ParserService: content, metadata
    else PDF文档且gRPC连接失败
        ParserService->>ParserService: PDFParser.parse(filePath)
        ParserService-->>DocumentService: content, metadata
    else DOCX文档且gRPC连接成功
        ParserService->>GRPCClient: ParseDOCX(filePath)
        GRPCClient->>PythonServer: gRPC请求
        PythonServer->>DOCXParser: parse(filePath)
        DOCXParser->>DOCXParser: python-docx解析
        DOCXParser-->>PythonServer: content, metadata
        PythonServer-->>GRPCClient: ParseDocumentResponse
        GRPCClient-->>ParserService: content, metadata
    else 其他文档类型
        ParserService->>ParserService: 本地解析器
        ParserService-->>DocumentService: content, metadata
    end
    ParserService-->>DocumentService: content, metadata
```

### 技术实现细节

#### 1. 解析器选择策略

- **优先级机制**：gRPC解析器优先于本地解析器
- **容错设计**：gRPC服务不可用时自动降级
- **类型映射**：根据文件扩展名自动选择解析器

#### 2. 元数据提取

- **PDF元数据**：标题、作者、页数、表格数、图片数
- **DOCX元数据**：标题、作者、段落数、表格数、超链接数
- **统一格式**：所有元数据转换为字符串，便于存储

#### 3. 错误处理机制

- **渐进式降级**：单页解析失败不影响整体
- **编码容错**：自动清理非UTF-8字符
- **日志记录**：详细的错误日志便于排查

#### 4. 性能优化

- **并发处理**：Python服务支持多线程处理
- **流式处理**：大文件分页解析，避免内存溢出
- **缓存策略**：解析结果缓存，减少重复解析

### PDF解析详细流程

```mermaid
flowchart TD
    Start[开始解析PDF] --> CheckFile{文件存在?}
    CheckFile -->|否| Error1[返回文件不存在错误]
    CheckFile -->|是| GetSize[获取文件大小]
    GetSize --> OpenFile[打开文件]
    OpenFile --> ReadPDF[PyPDF2读取]
    ReadPDF --> GetPages[获取页数]
    GetPages --> LoopPages{循环处理每页}
    LoopPages -->|有下一页| ExtractPage[提取页面文本]
    ExtractPage --> CheckUTF8{UTF-8编码检查}
    CheckUTF8 -->|有效| AddContent[添加到内容]
    CheckUTF8 -->|无效| CleanText[清理非UTF-8字符]
    CleanText --> AddContent
    AddContent --> NextPage[处理下一页]
    NextPage --> LoopPages
    LoopPages -->|完成| ExtractMeta[pdfplumber提取元数据]
    ExtractMeta --> BuildMeta[构建元数据字典]
    BuildMeta --> AddBasic[添加基本元数据]
    AddBasic --> Return[返回内容和元数据]
    
    style Start fill:#e1f5fe
    style Return fill:#c8e6c9
    style Error1 fill:#ffcdd2
```

### gRPC通信机制详解

```mermaid
sequenceDiagram
    participant GoService as Go解析服务
    participant GRPCClient as gRPC客户端
    participant Server as Python gRPC服务器
    participant PDFParser as PDF解析器
    participant DOCXParser as DOCX解析器
    
    GoService->>GRPCClient: 初始化连接
    GRPCClient->>Server: 建立gRPC连接
    Server-->>GRPCClient: 连接成功
    
    Note over GoService,Server: 协议缓冲区定义
    GoService->>GRPCClient: ParsePDF请求
    GRPCClient->>Server: gRPC调用流1
    Server->>PDFParser: 调用解析方法
    PDFParser->>PDFParser: PyPDF2提取文本
    PDFParser->>PDFParser: pdfplumber提取元数据
    PDFParser-->>Server: 返回内容和元数据
    Server->>Server: 转换为protobuf格式
    Server-->>GRPCClient: ParsePDF响应
    GRPCClient-->>GoService: 解析结果
    
    GoService->>GRPCClient: ParseDOCX请求
    GRPCClient->>Server: gRPC调用流2
    Server->>DOCXParser: 调用解析方法
    DOCXParser->>DOCXParser: python-docx解析
    DOCXParser-->>Server: 返回内容和元数据
    Server->>Server: 转换为protobuf格式
    Server-->>GRPCClient: ParseDocument响应
    GRPCClient-->>GoService: 解析结果
    
    Note over GoService,Server: 连接失败降级
    GoService->>GoService: 使用本地解析器
```

## feature-semantic-search (语义检索功能)

### 设计理念

语义检索功能采用混合检索策略，结合关键词搜索和向量相似度搜索，实现精准的文档查找。通过OpenAI Embedding API生成文档向量，使用pgvector实现高效的向量相似度计算，支持毫秒级的语义搜索响应。

### 架构设计

#### 检索服务架构

```mermaid
graph TB
    A[SearchService] --> B[SearchIndexRepository]
    A --> C[EmbeddingService]
    A --> D[CacheService]
    C --> E[OpenAI API]
    B --> F[PostgreSQL with pgvector]
    D --> G[Redis]
    
    A --> H{搜索类型}
    H -->|keyword| I[关键词搜索]
    H -->|semantic| J[语义搜索]
    H -->|hybrid| K[混合搜索]
    
    I --> B
    J --> C
    J --> B
    K --> I
    K --> J
    K --> L[结果合并]
```

### 实现深度剖析

#### 搜索服务核心

[`SearchService.Search()`](internal/service/search_service.go:97) 方法实现了完整的搜索逻辑：

```go
func (s *searchService) Search(ctx context.Context, request *model.SearchRequest) 
    (*model.SearchResponse, error) {
    
    // 1. 生成缓存键
    cacheKey := searchCacheKey(request.Query, request.SearchType, 
        request.Filters, request.Page, request.Size)
    
    // 2. 尝试从缓存获取结果
    if cachedResult, found := s.cacheService.Get(cacheKey); found {
        if response, ok := cachedResult.(*model.SearchResponse); ok {
            return response, nil
        }
    }
    
    var indices []*model.SearchIndex
    var total int64
    var err error
    
    startTime := time.Now()
    
    // 3. 根据搜索类型执行不同的搜索策略
    switch request.SearchType {
    case "keyword":
        // 关键词搜索
        keywords := s.extractKeywords(request.Query)
        indices, total, err = s.indexRepo.SearchByKeywords(ctx, keywords, 
            request.Filters, request.Page, request.Size)
        for _, index := range indices {
            index.Score = s.calculateRelevanceScore(index, request.Query, "keyword")
        }
        
    case "semantic":
        // 语义搜索
        queryVector := s.generateQueryVector(request.Query)
        indices, total, err = s.indexRepo.SearchByVector(ctx, queryVector, 
            request.Filters, request.Page, request.Size)
        for _, index := range indices {
            index.Score = s.calculateRelevanceScore(index, request.Query, "semantic")
        }
        
    case "hybrid":
        // 混合搜索
        var keywordIndices, semanticIndices []*model.SearchIndex
        var keywordTotal, semanticTotal int64
        
        // 关键词搜索
        keywords := s.extractKeywords(request.Query)
        keywordIndices, keywordTotal, err = s.indexRepo.SearchByKeywords(ctx, 
            keywords, request.Filters, request.Page, request.Size)
        for _, index := range keywordIndices {
            index.Score = s.calculateRelevanceScore(index, request.Query, "keyword")
        }
        
        // 语义搜索
        queryVector := s.generateQueryVector(request.Query)
        semanticIndices, semanticTotal, err = s.indexRepo.SearchByVector(ctx, 
            queryVector, request.Filters, request.Page, request.Size)
        for _, index := range semanticIndices {
            index.Score = s.calculateRelevanceScore(index, request.Query, "semantic")
        }
        
        // 合并结果
        indices, total = s.mergeSearchResults(keywordIndices, semanticIndices, 
            keywordTotal, semanticTotal)
    }
    
    if err != nil {
        return nil, fmt.Errorf("search failed: %v", err)
    }
    
    // 4. 计算搜索耗时
    duration := time.Since(startTime)
    
    // 5. 转换为搜索结果
    results := s.convertToSearchResults(indices)
    
    response := &model.SearchResponse{
        Total: total,
        Items: results,
        Page:  request.Page,
        Size:  request.Size,
    }
    
    // 6. 智能缓存策略
    s.applyCacheStrategy(cacheKey, response, duration, request)
    
    return response, nil
}
```

#### 向量化服务

[`EmbeddingService`](internal/service/embedding_service.go:19) 封装了OpenAI Embedding API的调用：

```go
type openAIEmbeddingService struct {
    client *openai.Client
    model  openai.EmbeddingModel
}

func NewOpenAIEmbeddingService(apiKey, modelStr string) EmbeddingService {
    // 从环境变量获取API Key
    if apiKey == "" {
        apiKey = os.Getenv("OPENAI_API_KEY")
    }
    
    config := openai.DefaultConfig(apiKey)
    
    // 支持自定义API Base URL
    if baseURL := os.Getenv("OPENAI_BASE_URL"); baseURL != "" {
        config.BaseURL = baseURL
    }
    
    client := openai.NewClientWithConfig(config)
    
    var model openai.EmbeddingModel
    if modelStr == "" {
        model = openai.AdaEmbeddingV2  // 默认模型
    } else {
        model = openai.EmbeddingModel(modelStr)
    }
    
    return &openAIEmbeddingService{
        client: client,
        model:  model,
    }
}

func (s *openAIEmbeddingService) GenerateEmbedding(ctx context.Context, 
    content string) ([]float32, error) {
    // 1. 内容验证
    if strings.TrimSpace(content) == "" {
        return nil, fmt.Errorf("content is empty")
    }
    
    // 2. 内容截断（OpenAI API限制）
    if len(content) > 8192 {
        content = content[:8192]
        log.Printf("Warning: Content truncated to 8192 characters")
    }
    
    // 3. 创建嵌入请求
    req := openai.EmbeddingRequest{
        Input: []string{content},
        Model: s.model,
    }
    
    // 4. 调用OpenAI API
    resp, err := s.client.CreateEmbeddings(ctx, req)
    if err != nil {
        log.Printf("Error generating embedding: %v", err)
        return nil, fmt.Errorf("failed to generate embedding: %v", err)
    }
    
    // 5. 验证响应
    if len(resp.Data) == 0 {
        return nil, fmt.Errorf("no embedding data returned")
    }
    
    return resp.Data[0].Embedding, nil
}
```

**技术要点**：
- **API封装**：封装OpenAI API调用，提供统一接口
- **错误处理**：详细的错误日志和返回信息
- **配置灵活**：支持自定义API Key和Base URL
- **内容截断**：自动处理超长内容，符合API限制

#### 索引构建

[`SearchService.BuildIndex()`](internal/service/search_service.go:57) 方法实现文档索引的构建：

```go
func (s *searchService) BuildIndex(ctx context.Context, documentID, version string) error {
    // 1. 获取文档版本信息
    docVersion, err := s.versionRepo.GetByDocumentIDAndVersion(ctx, documentID, version)
    if err != nil {
        return fmt.Errorf("failed to get document version: %v", err)
    }
    
    // 2. 检查文档状态
    if docVersion.Status != model.DocumentStatusCompleted {
        return fmt.Errorf("document is not ready for indexing, status: %s", 
            docVersion.Status)
    }
    
    // 3. 获取文档信息
    document, err := s.documentRepo.GetByID(ctx, documentID)
    if err != nil {
        return fmt.Errorf("failed to get document: %v", err)
    }
    
    // 4. 解析文档内容并构建索引
    indices, err := s.parseAndBuildIndices(document, docVersion)
    if err != nil {
        return fmt.Errorf("failed to parse and build indices: %v", err)
    }
    
    return nil
}

func (s *searchService) parseAndBuildIndices(document *model.Document, 
    docVersion *model.DocumentVersion) ([]*model.SearchIndex, error) {
    
    // 1. 提取文档内容
    content := docVersion.Content
    
    // 2. 生成向量
    embedding := s.generateEmbedding(content)
    vectorSlice := s.generateContentVector(content)
    
    // 3. 将向量转换为JSON字符串
    vectorJSON, err := json.Marshal(vectorSlice)
    if err != nil {
        log.Printf("Error marshaling vector to JSON: %v", err)
        vectorJSON = []byte("[]")
    }
    
    // 4. 创建单个索引条目
    newID := generateID()
    index := &model.SearchIndex{
        ID:          newID,
        DocumentID:  document.ID,
        Version:     docVersion.Version,
        Content:     content,
        ContentType: "text",
        Section:     document.Name,
        Keywords:    "",
        Vector:      string(vectorJSON),
        Embedding:   embedding,
        Metadata:    s.buildSimpleMetadata(document, docVersion),
        CreatedAt:   time.Now(),
    }
    
    // 5. 删除旧索引
    if err := s.indexRepo.DeleteByDocumentIDAndVersion(context.Background(), 
        document.ID, docVersion.Version); err != nil {
        log.Printf("Error deleting old indices: %v", err)
    }
    
    // 6. 创建新索引
    if err := s.indexRepo.CreateBatch(context.Background(), []*model.SearchIndex{index}); err != nil {
        return nil, fmt.Errorf("failed to create search indices: %v", err)
    }
    
    return []*model.SearchIndex{index}, nil
}
```

### 语义搜索流程

```mermaid
sequenceDiagram
    participant Client
    participant SearchService
    participant CacheService
    participant EmbeddingService
    participant OpenAI_API
    participant SearchIndexRepository
    participant PostgreSQL
    
    Client->>SearchService: Search(query, type)
    SearchService->>CacheService: Get(cacheKey)
    alt 缓存命中
        CacheService-->>SearchService: cached result
        SearchService-->>Client: 返回缓存结果
    else 缓存未命中
        SearchService->>SearchService: 提取关键词
        SearchService->>EmbeddingService: GenerateEmbedding(query)
        EmbeddingService->>OpenAI_API: CreateEmbeddings()
        OpenAI_API-->>EmbeddingService: 向量数据
        EmbeddingService-->>SearchService: queryVector
        
        alt 关键词搜索
            SearchService->>SearchIndexRepository: SearchByKeywords()
            SearchIndexRepository->>PostgreSQL: LIKE查询
            PostgreSQL-->>SearchIndexRepository: 结果
            SearchIndexRepository-->>SearchService: indices
        else 语义搜索
            SearchService->>SearchIndexRepository: SearchByVector()
            SearchIndexRepository->>PostgreSQL: 余弦相似度查询
            PostgreSQL-->>SearchIndexRepository: 结果
            SearchIndexRepository-->>SearchService: indices
        else 混合搜索
            SearchService->>SearchIndexRepository: SearchByKeywords()
            SearchService->>SearchIndexRepository: SearchByVector()
            SearchService->>SearchService: mergeSearchResults()
            SearchService-->>SearchService: 合并结果
        end
        
        SearchService->>SearchService: 计算相关性得分
        SearchService->>CacheService: Set(cacheKey, response)
        SearchService-->>Client: 搜索结果
    end
```

### 向量存储架构详解

```mermaid
graph LR
    A[文档内容] --> B[OpenAI Embedding API]
    B --> C[1536维向量]
    C --> D[向量归一化]
    D --> E[PostgreSQL pgvector]
    
    E --> F[索引类型]
    F --> G[IVFFlat索引]
    F --> H[HNSW索引]
    
    G --> I[查询优化]
    H --> I
    
    I --> J[余弦相似度]
    J --> K[Top-K结果]
    
    L[Redis缓存] --> M[查询结果缓存]
    N[搜索请求] --> O{缓存命中?}
    O -->|是| P[返回缓存结果]
    O -->|否| Q[执行向量搜索]
    Q --> R[生成查询向量]
    R --> S[pgvector相似度查询]
    S --> T[返回相似文档]
    T --> U[存入缓存]
    U --> V[返回结果]
    
    style A fill:#e1f5fe
    style K fill:#c8e6c9
    style P fill:#fff9c4
    style V fill:#c8e6c9
```

### 混合检索算法详解

```mermaid
flowchart TB
    Start[接收搜索请求] --> ParseQuery[解析查询语句]
    ParseQuery --> CheckCache{检查缓存}
    CheckCache -->|命中| ReturnCache[返回缓存结果]
    CheckCache -->|未命中| DetermineType{搜索类型}
    
    DetermineType -->|关键词| ExtractKeywords[提取关键词]
    ExtractKeywords --> KeywordSearch[关键词搜索]
    KeywordSearch --> KeywordScore[计算相关性得分]
    
    DetermineType -->|语义| GenerateEmbedding[生成查询向量]
    GenerateEmbedding --> VectorSearch[向量相似度搜索]
    VectorSearch --> VectorScore[计算相似度得分]
    
    DetermineType -->|混合| Parallel[并行执行]
    Parallel --> ExtractKeywords
    Parallel --> GenerateEmbedding
    KeywordScore --> MergeResults
    VectorScore --> MergeResults
    
    MergeResults[合并搜索结果] --> ApplyWeight[应用权重]
    ApplyWeight --> ReRank[重新排序]
    ReRank --> ApplyFilter[应用过滤条件]
    ApplyFilter --> Paginate[分页处理]
    Paginate --> CalculateScore[计算最终得分]
    CalculateScore --> CacheResult[缓存结果]
    CacheResult --> Return[返回搜索结果]
    ReturnCache --> End[结束]
    Return --> End
    
    style Start fill:#e1f5fe
    style ReturnCache fill:#fff9c4
    style Return fill:#c8e6c9
    style End fill:#c8e6c9
```

### 实际使用示例

#### 语义搜索示例

**1. 关键词搜索**：
```bash
curl -X GET "http://localhost:8080/api/search?query=REST API&type=keyword&page=1&size=10" \
  -H "Authorization: Bearer YOUR_JWT_TOKEN"
```

响应示例：
```json
{
  "code": 200,
  "data": {
    "total": 15,
    "items": [
      {
        "document_id": "doc-123",
        "version": "1.0.0",
        "content": "RESTful API接口文档...",
        "score": 0.95,
        "metadata": {
          "name": "API文档",
          "type": "docx"
        }
      }
    ],
    "page": 1,
    "size": 10
  }
}
```

**2. 语义搜索**：
```bash
curl -X GET "http://localhost:8080/api/search?query=如何上传文档&type=semantic&page=1&size=5" \
  -H "Authorization: Bearer YOUR_JWT_TOKEN"
```

**3. 混合搜索**：
```bash
curl -X GET "http://localhost:8080/api/search?query=API文档上传&type=hybrid&page=1&size=10" \
  -H "Authorization: Bearer YOUR_JWT_TOKEN"
```

**4. 带过滤条件的搜索**：
```bash
curl -X GET "http://localhost:8080/api/search?query=API&type=semantic&library=my-library&version=1.0.0" \
  -H "Authorization: Bearer YOUR_JWT_TOKEN"
```

### 技术实现细节

#### 1. 向量存储机制详解

**pgvector扩展配置**：
```sql
-- 启用pgvector扩展
CREATE EXTENSION IF NOT EXISTS vector;

-- 创建向量索引
CREATE INDEX ON search_indices
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

-- 创建传统向量索引（JSON格式）
CREATE INDEX ON search_indices USING gin (vector jsonb_path_ops);
```

**向量归一化算法**：
```go
func (s *searchService) normalizeVector(vector []float32) []float32 {
    var norm float32
    for _, v := range vector {
        norm += v * v
    }
    if norm > 0 {
        norm = float32(math.Sqrt(float64(norm)))
        for i := range vector {
            vector[i] /= norm
        }
    }
    return vector
}
```

**余弦相似度计算**：
```sql
-- 查询最相似的文档（余弦相似度）
SELECT id, document_id, version, content,
       1 - (embedding <=> query_vector) as similarity
FROM search_indices
ORDER BY embedding <=> query_vector
LIMIT 10;
```

其中`<=>`是pgvector提供的余弦距离操作符，距离越小表示越相似。


- **pgvector扩展**：使用PostgreSQL的pgvector扩展存储向量
- **JSON格式**：传统向量以JSON字符串格式存储
- **专用字段**：Embedding向量使用专用字段存储
- **索引优化**：在vector字段上建立索引加速查询

#### 2. 相似度计算

- **余弦相似度**：使用余弦相似度计算向量相似度
- **归一化处理**：所有向量在存储前进行归一化
- **批量查询**：支持批量向量相似度查询

#### 3. 混合检索策略

- **关键词搜索**：基于文本匹配的传统搜索
- **语义搜索**：基于向量相似度的语义检索
- **结果合并**：智能合并两种搜索结果
- **权重调整**：根据相关性得分调整结果排序

#### 4. 缓存策略

- **智能缓存**：根据查询复杂度决定是否缓存
- **TTL管理**：设置合理的缓存过期时间
- **缓存失效**：内容更新时主动失效缓存

### 性能优化

1. **向量索引**：使用pgvector的IVFFlat索引加速查询
2. **批量处理**：支持批量向量和索引创建
3. **异步索引**：文档解析完成后异步创建索引
4. **查询优化**：使用EXPLAIN ANALYZE优化SQL查询

## feature-user-authentication (用户认证功能)

### 设计理念

用户认证功能采用JWT（JSON Web Token）无状态认证机制，结合bcrypt密码加密算法，提供安全的用户身份验证和授权管理。支持用户注册、登录、密码重置、令牌刷新等完整的用户认证生命周期管理。

### 架构设计

#### 认证架构

```mermaid
graph TB
    A[用户认证流程] --> B[用户注册]
    A --> C[用户登录]
    A --> D[密码重置]
    
    B --> E[UserService.Register]
    C --> F[UserService.Login]
    D --> G[UserService.RequestPasswordReset]
    
    E --> H[密码加密]
    E --> I[创建用户记录]
    
    F --> J[密码验证]
    F --> K[生成JWT]
    F --> L[生成RefreshToken]
    
    G --> M[生成重置令牌]
    G --> N[发送邮件]
    
    H --> O[bcrypt哈希]
    J --> O
    K --> P[JWT Claims]
    L --> Q[随机令牌]
```

### 实现深度剖析

#### 用户认证实际示例

**1. 用户注册**：
```bash
curl -X POST http://localhost:8080/api/users/register \
  -H "Content-Type: application/json" \
  -d '{
    "username": "testuser",
    "email": "test@example.com",
    "password": "SecurePass123",
    "first_name": "Test",
    "last_name": "User"
  }'
```

响应：
```json
{
  "message": "注册成功",
  "user": {
    "id": "user-123",
    "username": "testuser",
    "email": "test@example.com",
    "role": "user",
    "is_active": true,
    "created_at": "2024-01-01T00:00:00Z"
  }
}
```

**2. 用户登录**：
```bash
curl -X POST http://localhost:8080/api/users/login \
  -H "Content-Type: application/json" \
  -d '{
    "username": "testuser",
    "password": "SecurePass123"
  }'
```

响应：
```json
{
  "user": {
    "id": "user-123",
    "username": "testuser",
    "email": "test@example.com",
    "role": "user"
  },
  "access_token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
  "refresh_token": "rt-xxx-yyy-zzz",
  "expires_in": 3600,
  "token_type": "Bearer"
}
```

**3. 使用JWT访问受保护资源**：
```bash
curl -X GET http://localhost:8080/api/documents \
  -H "Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..."
```

**4. 刷新令牌**：
```bash
curl -X POST http://localhost:8080/api/users/refresh \
  -H "Content-Type: application/json" \
  -d '{
    "refresh_token": "rt-xxx-yyy-zzz"
  }'
```

### 用户注册实现深度剖析

[`UserService.Register()`](internal/service/user_service.go:88) 方法实现用户注册：

```go
func (s *userService) Register(ctx context.Context, req *model.UserRegister) 
    (*model.UserResponse, error) {
    
    // 1. 检查用户名是否已存在
    exists, err := s.userRepo.ExistsByUsername(req.Username)
    if err != nil {
        return nil, fmt.Errorf("检查用户名失败: %v", err)
    }
    if exists {
        return nil, fmt.Errorf("用户名已存在")
    }
    
    // 2. 检查邮箱是否已存在
    exists, err = s.userRepo.ExistsByEmail(req.Email)
    if err != nil {
        return nil, fmt.Errorf("检查邮箱失败: %v", err)
    }
    if exists {
        return nil, fmt.Errorf("邮箱已存在")
    }
    
    // 3. 加密密码
    hashedPassword, err := bcrypt.GenerateFromPassword([]byte(req.Password), 
        bcrypt.DefaultCost)
    if err != nil {
        return nil, fmt.Errorf("密码加密失败: %v", err)
    }
    
    // 4. 创建用户
    user := &model.User{
        Username:     req.Username,
        Email:        req.Email,
        PasswordHash: string(hashedPassword),
        FirstName:    req.FirstName,
        LastName:     req.LastName,
        Role:         "user",  // 默认角色
        IsActive:     true,
    }
    
    err = s.userRepo.Create(user)
    if err != nil {
        return nil, fmt.Errorf("创建用户失败: %v", err)
    }
    
    return user.ToResponse(), nil
}
```

**安全措施**：
- **唯一性验证**：确保用户名和邮箱的唯一性
- **密码加密**：使用bcrypt算法加密密码，成本系数为10
- **默认角色**：新用户默认分配"user"角色
- **数据隔离**：响应数据不包含敏感信息

#### 用户登录

[`UserService.Login()`](internal/service/user_service.go:133) 方法实现用户登录：

```go
func (s *userService) Login(ctx context.Context, req *model.UserLogin) 
    (*model.LoginResponse, error) {
    
    // 1. 根据用户名或邮箱查找用户
    var user *model.User
    var err error
    
    if strings.Contains(req.Username, "@") {
        user, err = s.userRepo.GetByEmail(req.Username)
    } else {
        user, err = s.userRepo.GetByUsername(req.Username)
    }
    
    if err != nil {
        return nil, fmt.Errorf("用户不存在")
    }
    
    // 2. 检查用户是否激活
    if !user.IsActive {
        return nil, fmt.Errorf("用户账户已被禁用")
    }
    
    // 3. 验证密码
    err = bcrypt.CompareHashAndPassword([]byte(user.PasswordHash), []byte(req.Password))
    if err != nil {
        return nil, fmt.Errorf("密码错误")
    }
    
    // 4. 更新最后登录时间
    err = s.userRepo.UpdateLastLogin(user.ID)
    if err != nil {
        fmt.Printf("更新最后登录时间失败: %v\n", err)
    }
    
    // 5. 生成JWT令牌
    accessToken, err := s.GenerateJWT(user)
    if err != nil {
        return nil, fmt.Errorf("生成访问令牌失败: %v", err)
    }
    
    // 6. 生成刷新令牌
    refreshToken, err := s.generateRefreshToken()
    if err != nil {
        return nil, fmt.Errorf("生成刷新令牌失败: %v", err)
    }
    
    return &model.LoginResponse{
        User:         user.ToResponse(),
        AccessToken:  accessToken,
        RefreshToken: refreshToken,
        ExpiresIn:    int64(s.jwtExpiration.Seconds()),
        TokenType:    "Bearer",
    }, nil
}
```

**登录流程**：
- **灵活登录**：支持用户名或邮箱登录
- **账户验证**：检查账户是否激活
- **密码验证**：使用bcrypt.CompareHashAndPassword验证密码
- **双令牌机制**：生成AccessToken和RefreshToken

#### JWT令牌生成

[`UserService.GenerateJWT()`](internal/service/user_service.go:415) 方法生成JWT令牌：

```go
func (s *userService) GenerateJWT(user *model.User) (string, error) {
    // 1. 创建JWT Claims
    claims := jwt.MapClaims{
        "user_id":  user.ID,
        "username": user.Username,
        "role":     user.Role,
        "exp":      time.Now().Add(s.jwtExpiration).Unix(),
        "iat":      time.Now().Unix(),
    }
    
    // 2. 生成令牌
    token := jwt.NewWithClaims(jwt.SigningMethodHS256, claims)
    
    // 3. 签名令牌
    tokenString, err := token.SignedString([]byte(s.jwtSecret))
    if err != nil {
        return "", fmt.Errorf("failed to sign token: %v", err)
    }
    
    return tokenString, nil
}
```

**JWT特性**：
- **HS256算法**：使用HMAC SHA-256签名算法
- **载荷内容**：包含用户ID、用户名、角色等信息
- **过期时间**：令牌包含exp字段，自动过期
- **签名密钥**：使用配置的JWT Secret签名

#### 认证中间件

[`AuthMiddleware.RequireAuth()`](internal/middleware/auth.go:24) 实现认证中间件：

```go
func (m *AuthMiddleware) RequireAuth() gin.HandlerFunc {
    return func(c *gin.Context) {
        // 1. 获取Authorization头
        authHeader := c.GetHeader("Authorization")
        if authHeader == "" {
            c.JSON(http.StatusUnauthorized, gin.H{
                "error": "缺少授权令牌",
            })
            c.Abort()
            return
        }
        
        // 2. 检查Bearer前缀
        if !strings.HasPrefix(authHeader, "Bearer ") {
            c.JSON(http.StatusUnauthorized, gin.H{
                "error": "无效的授权格式",
            })
            c.Abort()
            return
        }
        
        // 3. 提取令牌
        tokenString := authHeader[7:]
        
        // 4. 验证令牌
        claims, err := m.userService.ValidateJWT(tokenString)
        if err != nil {
            c.JSON(http.StatusUnauthorized, gin.H{
                "error": "无效的授权令牌",
            })
            c.Abort()
            return
        }
        
        // 5. 将用户信息存储到上下文中
        c.Set("user_id", claims.UserID)
        c.Set("username", claims.Username)
        c.Set("role", claims.Role)
        
        c.Next()
    }
}
```

**中间件功能**：
- **令牌提取**：从Authorization头提取Bearer令牌
- **令牌验证**：调用UserService验证令牌有效性
- **上下文注入**：将用户信息注入到Gin上下文
- **优雅拒绝**：认证失败时返回401状态码

### 用户认证流程

```mermaid
sequenceDiagram
    participant Client
    participant AuthMiddleware
    participant UserService
    participant UserRepository
    participant Database
    
    Client->>AuthService: Register(username, email, password)
    AuthService->>AuthService: 验证用户名和邮箱唯一性
    AuthService->>AuthService: bcrypt加密密码
    AuthService->>UserRepository: Create(user)
    UserRepository->>Database: INSERT INTO users
    Database-->>UserRepository: 用户记录
    UserRepository-->>AuthService: user
    AuthService-->>Client: UserResponse
    
    Client->>AuthService: Login(username, password)
    AuthService->>UserRepository: GetByUsername(username)
    UserRepository->>Database: SELECT FROM users
    Database-->>UserRepository: user
    UserRepository-->>AuthService: user
    AuthService->>AuthService: bcrypt验证密码
    AuthService->>UserService: GenerateJWT(user)
    UserService-->>AuthService: accessToken
    AuthService->>AuthService: generateRefreshToken()
    AuthService-->>Client: LoginResponse
    
    Client->>AuthMiddleware: Request with Authorization
    AuthMiddleware->>AuthMiddleware: 提取Bearer Token
    AuthMiddleware->>UserService: ValidateJWT(token)
    UserService->>UserService: 验证签名和过期时间
    UserService-->>AuthMiddleware: claims
    AuthMiddleware->>AuthMiddleware: 注入用户信息到context
    AuthMiddleware->>Handler: 继续处理请求
```

### 技术实现细节

#### 1. 密码安全

- **bcrypt哈希**：使用bcrypt算法进行密码哈希
- **成本系数**：默认使用bcrypt.DefaultCost（10）
- **盐值自动**：bcrypt自动生成和管理盐值
- **单向加密**：密码无法反向解密

#### 2. JWT令牌管理

- **无状态认证**：JWT令牌包含所有必要信息
- **过期机制**：令牌设置合理的过期时间
- **刷新令牌**：使用RefreshToken延长会话
- **签名验证**：使用HS256算法签名验证

#### 3. 角色权限控制

- **三种角色**：admin、editor、user
- **中间件支持**：RequireRole中间件实现角色验证
- **灵活配置**：支持多角色验证
- **默认角色**：新用户默认分配"user"角色

#### 4. 密码重置机制

- **令牌生成**：生成唯一的重置令牌
- **过期时间**：重置令牌设置过期时间
- **邮件发送**：发送包含重置链接的邮件
- **令牌验证**：验证令牌有效性后允许重置密码

### 安全性考虑

1. **密码复杂度**：注册时验证密码长度至少6位
2. **令牌传输**：使用HTTPS传输令牌
3. **令牌存储**：建议存储在HttpOnly Cookie中
4. **CSRF防护**：结合CSRF Token使用
5. **速率限制**：实施登录尝试速率限制

## feature-api-key-management (API密钥管理功能)

### 设计理念

API密钥管理功能提供程序化访问系统的安全机制，支持API密钥的生成、存储、验证和失效管理。通过API密钥，第三方应用可以安全地访问系统提供的MCP服务和其他API接口，实现自动化的文档管理和检索操作。

### 实现深度剖析

#### API密钥认证中间件

[`AuthMiddleware.APIKeyAuth()`](internal/middleware/auth.go:142) 实现API密钥认证：

```go
func (m *AuthMiddleware) APIKeyAuth() gin.HandlerFunc {
    return func(c *gin.Context) {
        // 1. 获取API密钥
        apiKey := c.GetHeader("API_KEY")
        if apiKey == "" {
            // 尝试从Authorization头获取
            authHeader := c.GetHeader("Authorization")
            if strings.HasPrefix(authHeader, "Bearer ") {
                apiKey = strings.TrimPrefix(authHeader, "Bearer ")
            }
        }
        
        if apiKey == "" {
            c.JSON(http.StatusUnauthorized, gin.H{
                "error": "API密钥是必需的",
            })
            c.Abort()
            return
        }
        
        // 2. 将API密钥存储到上下文中
        c.Set("api_key", apiKey)
        
        c.Next()
    }
}
```

**认证机制**：
- **多来源获取**：支持从API_KEY头和Authorization头获取
- **Bearer格式**：支持Bearer Token格式
- **上下文注入**：将API密钥注入到请求上下文

#### MCP服务中的API密钥管理

MCP（Model Context Protocol）服务集成了API密钥管理功能：

```go
// MCP API密钥模型
type MCPApiKey struct {
    ID        string    `json:"id" gorm:"primaryKey"`
    Name      string    `json:"name" gorm:"not null"`
    Key       string    `json:"key" gorm:"uniqueIndex;not null"`
    Enabled   bool      `json:"enabled" gorm:"default:true"`
    CreatedAt time.Time `json:"created_at" gorm:"autoCreateTime"`
    UpdatedAt time.Time `json:"updated_at" gorm:"autoUpdateTime"`
}
```

### API密钥管理流程

```mermaid
sequenceDiagram
    participant Admin
    participant MCPService
    participant MCPApiKeyRepository
    participant Database
    participant Client
    
    Admin->>MCPService: CreateApiKey(name)
    MCPService->>MCPService: 生成随机密钥
    MCPService->>MCPService: 加密密钥
    MCPService->>MCPApiKeyRepository: Create(mcpApiKey)
    MCPApiKeyRepository->>Database: INSERT INTO mcp_api_keys
    Database-->>MCPApiKeyRepository: mcpApiKey
    MCPApiKeyRepository-->>MCPService: apiKey
    MCPService-->>Admin: API Key (仅显示一次)
    
    Client->>MCPService: Request with API_KEY
    MCPService->>MCPApiKeyRepository: GetByKey(apiKey)
    MCPApiKeyRepository->>Database: SELECT FROM mcp_api_keys
    Database-->>MCPApiKeyRepository: mcpApiKey
    MCPApiKeyRepository-->>MCPService: mcpApiKey
    MCPService->>MCPService: 验证密钥有效性
    alt 密钥有效且启用
        MCPService->>Client: 处理请求
    else 密钥无效或禁用
        MCPService-->>Client: 401 Unauthorized
    end
```

### 技术实现细节

#### 1. 密钥生成策略

- **随机生成**：使用加密安全的随机数生成器
- **足够长度**：密钥长度至少32个字符
- **唯一性保证**：数据库唯一索引确保密钥唯一
- **安全存储**：密钥使用加密算法存储

#### 2. 密钥验证机制

- **存在性检查**：验证密钥是否存在于数据库
- **启用状态**：检查密钥的enabled状态
- **性能优化**：缓存常用密钥的验证结果
- **审计日志**：记录密钥使用情况

#### 3. 密钥失效管理

- **手动失效**：管理员可以禁用特定密钥
- **自动过期**：支持设置密钥过期时间
- **定期清理**：清理长时间未使用的密钥
- **密钥轮换**：支持密钥定期轮换机制

#### 4. 权限绑定

- **密钥级别权限**：每个密钥可以配置不同的权限
- **访问控制**：限制密钥可访问的资源
- **操作审计**：记录密钥的所有操作
- **限流保护**：为密钥设置速率限制

### 安全性考虑

1. **密钥加密**：使用强加密算法存储密钥
2. **HTTPS传输**：强制使用HTTPS传输密钥
3. **密钥轮换**：定期轮换API密钥
4. **最小权限**：遵循最小权限原则
5. **审计日志**：记录所有密钥使用情况

## feature-document-versioning (文档版本管理功能)

### 设计理念

文档版本管理功能实现了完整的文档版本控制机制，支持多版本文档的上传、存储、查询和对比。每个文档可以有多个版本，版本之间通过版本号进行标识，系统自动跟踪每个版本的状态和更新时间，实现文档的完整生命周期管理。

### 架构设计

#### 版本管理架构

```mermaid
graph TB
    A[文档版本管理] --> B[文档记录]
    A --> C[版本记录]
    
    B --> D[Document]
    B --> E[基本信息]
    B --> F[最新版本引用]
    
    C --> G[DocumentVersion]
    G --> H[版本号]
    G --> I[文件路径]
    G --> J[状态]
    G --> K[元数据]
    
    D -->|1:N| C
    
    L[上传新版本] --> M{同库文档存在?}
    M -->|是| N[复用document_id]
    M -->|否| O[创建新document]
    N --> P[创建新version]
    O --> P
    P --> Q[版本唯一性检查]
    Q -->|唯一| R[保存版本]
    Q -->|重复| S[返回错误]
```

### 实现深度剖析

#### 版本数据模型

[`DocumentVersion`](internal/model/document.go:63) 模型定义了版本记录的结构：

```go
type DocumentVersion struct {
    ID          string         `json:"id" gorm:"primaryKey"`
    DocumentID  string         `json:"document_id" gorm:"not null;index"`
    Version     string         `json:"version" gorm:"not null;index"`
    FilePath    string         `json:"file_path" gorm:"not null"`
    FileSize    int64          `json:"file_size" gorm:"not null"`
    Status      DocumentStatus `json:"status" gorm:"not null"`
    Description string         `json:"description"`
    Content     string         `json:"content" gorm:"type:text"`
    CreatedAt   time.Time      `json:"created_at" gorm:"autoCreateTime"`
    UpdatedAt   time.Time      `json:"updated_at" gorm:"autoUpdateTime"`
}
```

**模型特性**：
- **复合主键**：使用ID作为主键，但通过document_id和version建立联合索引
- **状态跟踪**：每个版本独立维护状态
- **内容存储**：支持存储解析后的文本内容
- **时间戳**：记录创建和更新时间

#### 版本创建流程

在[`DocumentService.UploadDocument()`](internal/service/document_service.go:70)中实现了版本创建的核心逻辑：

```go
// 1. 检查同库文档
existingDocs, _, err := s.documentRepo.List(ctx, 1, 100, map[string]any{
    "library": library,
})

// 2. 确定文档ID
var documentID string
if len(existingDocs) > 0 {
    documentID = existingDocs[0].ID  // 复用现有文档ID
} else {
    documentID = uuid.New().String()  // 创建新文档ID
}

// 3. 版本号唯一性检查
existingVersion, err := s.versionRepo.GetByDocumentIDAndVersion(ctx, 
    documentID, version)
if err == nil && existingVersion != nil {
    return nil, fmt.Errorf("版本号 %s 已存在，请使用不同的版本号", version)
}

// 4. 创建文档版本记录
documentVersion := &model.DocumentVersion{
    ID:          uuid.New().String(),
    DocumentID:  document.ID,
    Version:     version,
    FilePath:    filePath,
    FileSize:    file.Size,
    Status:      model.DocumentStatusProcessing,
    Description: description,
}

if err := s.versionRepo.Create(ctx, documentVersion); err != nil {
    // 清理已保存的文件
    os.Remove(filePath)
    if len(existingDocs) == 0 {
        s.documentRepo.Delete(ctx, documentID)
    }
    return nil, fmt.Errorf("failed to create document version record: %v", err)
}
```

**创建流程**：
- **同库检查**：通过library字段检查是否存在同库文档
- **ID复用**：同库文档复用相同的document_id
- **版本唯一性**：确保同一文档的版本号唯一
- **原子操作**：失败时清理所有已创建的资源

#### 版本查询

[`DocumentVersionRepository.GetLatestVersion()`](internal/repository/document_version_repository.go:93) 方法获取文档的最新版本：

```go
func (r *documentVersionRepository) GetLatestVersion(ctx context.Context, 
    documentID string) (*model.DocumentVersion, error) {
    var version model.DocumentVersion
    err := r.db.WithContext(ctx).
        Where("document_id = ? AND status = ?", documentID, 
            model.DocumentStatusCompleted).
        Order("updated_at DESC").
        First(&version).Error
    if err != nil {
        return nil, err
    }
    return &version, nil
}
```

**查询策略**：
- **状态过滤**：只返回状态为completed的版本
- **时间排序**：按更新时间降序排列
- **最新版本**：返回第一个匹配的版本

### 文档版本管理流程

```mermaid
sequenceDiagram
    participant Client
    participant DocumentHandler
    participant DocumentService
    participant DocumentRepository
    participant DocumentVersionRepository
    participant Storage
    participant Parser
    
    Client->>DocumentHandler: UploadDocument(name, version, library)
    DocumentHandler->>DocumentService: UploadDocument()
    
    DocumentService->>DocumentRepository: List(library)
    DocumentRepository-->>DocumentService: existingDocs
    
    alt 同库文档存在
        DocumentService->>DocumentService: 复用documentID
    else 同库文档不存在
        DocumentService->>DocumentService: 生成新的documentID
        DocumentService->>DocumentRepository: Create(document)
    end
    
    DocumentService->>DocumentVersionRepository: GetByDocumentIDAndVersion()
    DocumentVersionRepository-->>DocumentService: existingVersion
    
    alt 版本已存在
        DocumentService->>Storage: 删除文件
        DocumentService-->>Client: 版本已存在错误
    else 版本不存在
        DocumentService->>Storage: 创建存储目录
        DocumentService->>Storage: 保存文件
        DocumentService->>DocumentVersionRepository: Create(version)
        DocumentService->>Parser: 异步解析文档
        DocumentService-->>Client: 上传成功
    end
```

### 技术实现细节

#### 1. 版本存储策略

- **文件隔离**：每个版本的文件独立存储
- **目录结构**：使用`{baseStorageDir}/{documentID}/{filename}`结构
- **版本命名**：文件名保持原样，版本通过数据库记录区分
- **空间优化**：相同内容的文件可以考虑使用硬链接

#### 2. 版本号生成规则

- **用户指定**：版本号由用户在上传时指定
- **唯一性验证**：系统强制验证版本号唯一性
- **格式灵活**：支持任意字符串作为版本号
- **语义版本**：建议使用语义化版本号（如1.0.0）

#### 3. 版本对比算法

- **文本对比**：对比解析后的文本内容
- **元数据对比**：对比文件大小、创建时间等元数据
- **差异展示**：标记新增、删除、修改的内容
- **可视化**：使用差异可视化工具展示

#### 4. 版本回滚机制

- **历史保留**：所有版本历史永久保留
- **回滚操作**：将文档引用的版本切换到指定版本
- **元数据更新**：更新文档的最新版本引用
- **索引重建**：回滚后重建搜索索引

### 性能优化

1. **索引优化**：在document_id和version上建立联合索引
2. **查询缓存**：常用版本的查询结果缓存
3. **批量操作**：支持批量获取文档的版本列表
4. **懒加载**：只在需要时加载版本内容

## feature-tagging-system (标签系统功能)

### 设计理念

标签系统提供了灵活的分类和组织机制，允许用户为文档添加多个标签进行分类。标签存储在PostgreSQL的数组类型中，支持高效的标签查询和统计，实现了标签的多选题特性，为文档管理提供更灵活的分类方式。

### 实现深度剖析

#### 标签数据模型

标签通过[`Document`](internal/model/document.go:45)模型中的`Tags`字段实现：

```go
type Document struct {
    // ...
    Tags StringArray `json:"tags" gorm:"type:character varying[]"`
    // ...
}

// StringArray 自定义字符串数组类型
type StringArray []string

// Value 实现 driver.Valuer 接口
func (t StringArray) Value() (driver.Value, error) {
    if t == nil {
        return nil, nil
    }
    
    if len(t) == 0 {
        return "{}", nil
    }
    
    // 转换为 PostgreSQL 数组格式
    var result string
    result = "{"
    for i, item := range t {
        if i > 0 {
            result += ","
        }
        escaped := strings.ReplaceAll(item, "\"", "\\\"")
        result += "\"" + escaped + "\""
    }
    result += "}"
    
    return result, nil
}

// Scan 实现 sql.Scanner 接口
func (t *StringArray) Scan(value interface{}) error {
    if value == nil {
        *t = nil
        return nil
    }
    
    var str string
    switch v := value.(type) {
    case []byte:
        str = string(v)
    case string:
        str = v
    default:
        return fmt.Errorf("cannot scan %T into StringArray", value)
    }
    
    // 处理 PostgreSQL 数组格式
    if len(str) >= 2 && str[0] == '{' && str[len(str)-1] == '}' {
        content := str[1 : len(str)-1]
        if content == "" {
            *t = StringArray{}
            return nil
        }
        
        items := strings.Split(content, ",")
        result := make(StringArray, len(items))
        
        for i, item := range items {
            if len(item) >= 2 && item[0] == '"' && item[len(item)-1] == '"' {
                unquoted := item[1 : len(item)-1]
                result[i] = strings.ReplaceAll(unquoted, "\\\"", "\"")
            } else {
                result[i] = item
            }
        }
        
        *t = result
        return nil
    }
    
    return fmt.Errorf("failed to parse tags: %s", str)
}
```

**技术实现**：
- **PostgreSQL数组**：使用PostgreSQL的字符数组类型存储
- **自定义类型**：实现Value和Scan接口处理类型转换
- **格式转换**：自动处理GORM与PostgreSQL之间的格式转换
- **特殊字符处理**：正确处理转义字符和引号

#### 标签处理流程

在[`DocumentHandler.UploadDocument()`](internal/handler/document_handler.go:29)中处理标签：

```go
// 1. 获取标签字符串
tagsStr := c.PostForm("tags")

// 2. 解析标签数组
var tags []string
if tagsStr != "" {
    tags = strings.Split(tagsStr, ",")
    // 去除前后空格
    for i, tag := range tags {
        tags[i] = strings.TrimSpace(tag)
    }
}

// 3. 传递给服务层
document, err := h.documentService.UploadDocument(context.Background(), 
    file, name, docType, category, version, library, description, tags)
```

**处理逻辑**：
- **字符串分割**：使用逗号分割标签字符串
- **空格清理**：去除每个标签的前后空格
- **空值处理**：空标签字符串转换为空数组

### 标签系统架构

```mermaid
graph LR
    A[用户上传文档] --> B[输入标签字符串]
    B --> C[逗号分割]
    C --> D[清理空格]
    D --> E[标签数组]
    E --> F[StringArray类型]
    F --> G[GORM ORM]
    G --> H[PostgreSQL数组]
    
    I[标签查询] --> J{查询类型}
    J -->|精确匹配| K[ANY查询]
    J -->|包含关系| L[contains查询]
    J -->|标签统计| M[array_length]
    
    K --> N[返回匹配文档]
    L --> N
    M --> O[返回统计结果]
```

### 技术实现细节

#### 1. 标签存储

- **数组类型**：使用PostgreSQL的`varchar[]`类型
- **格式转换**：GORM自动处理Go切片与PostgreSQL数组的转换
- **索引支持**：支持在数组上建立GIN索引加速查询
- **特殊字符**：正确处理包含引号和逗号的标签

#### 2. 标签查询

- **精确匹配**：使用`ANY`和`ALL`操作符
- **包含查询**：使用`@>`操作符检查包含关系
- **重叠查询**：使用`&&`操作符检查数组重叠
- **大小写敏感**：默认大小写敏感，可自定义

#### 3. 标签统计

- **标签计数**：统计每个标签的使用次数
- **热门标签**：找出最常用的标签
- **文档统计**：统计包含特定标签的文档数量
- **聚合查询**：使用PostgreSQL的聚合函数

#### 4. 标签关联

- **多对多关系**：标签与文档是多对多关系
- **去重处理**：同一个文档不能重复添加相同标签
- **标签推荐**：根据文档内容推荐相关标签
- **标签继承**：支持标签的层次结构

### 性能优化

1. **GIN索引**：在tags字段上建立GIN索引加速查询
2. **查询优化**：使用适当的查询操作符提高效率
3. **缓存策略**：热门标签的统计结果缓存
4. **批量操作**：支持批量更新标签

## feature-category-management (分类管理功能)

### 设计理念

分类管理功能提供了文档的层次化分类组织方式，支持代码类和文档类两种基本分类。分类通过DocumentCategory枚举类型实现，为文档提供了一级分类能力，便于按类别进行文档管理和查询。

### 实现深度剖析

#### 分类数据模型

分类通过[`Document`](internal/model/document.go:45)模型中的`Category`字段实现：

```go
type Document struct {
    // ...
    Category DocumentCategory `json:"category" gorm:"not null;index"`
    // ...
}

// DocumentCategory 定义文档分类
type DocumentCategory string

const (
    CategoryCode     DocumentCategory = "code"
    CategoryDocument DocumentCategory = "document"
)
```

**模型特性**：
- **枚举类型**：使用字符串常量定义分类
- **索引支持**：在category字段上建立索引
- **强制要求**：category字段不能为空
- **类型安全**：编译时检查分类的有效性

#### 分类验证

在[`DocumentService.UploadDocument()`](internal/service/document_service.go:70)中进行分类验证：

```go
// 验证文档分类
documentCategory := model.DocumentCategory(category)
if !isValidDocumentCategory(documentCategory) {
    return nil, fmt.Errorf("invalid document category: %s", category)
}

func isValidDocumentCategory(category model.DocumentCategory) bool {
    switch category {
    case model.CategoryCode, model.CategoryDocument:
        return true
    default:
        return false
    }
}
```

**验证逻辑**：
- **类型转换**：将字符串转换为DocumentCategory类型
- **有效性检查**：验证分类是否在预定义列表中
- **错误提示**：返回详细的错误信息

#### 分类查询

在[`DocumentHandler.GetDocuments()`](internal/handler/document_handler.go:164)中支持按分类过滤：

```go
// 解析过滤条件
filters := make(map[string]interface{})

if docType := c.Query("type"); docType != "" {
    filters["type"] = model.DocumentType(docType)
}

// 分类过滤
filters["category"] = model.DocumentCategory(category)

// 调用服务层获取文档列表
documents, total, err := h.documentService.GetDocuments(context.Background(), 
    page, size, filters)
```

**查询功能**：
- **按分类过滤**：支持通过分类筛选文档
- **组合查询**：可以和其他条件组合查询
- **分页支持**：支持分页查询结果

### 分类管理架构

```mermaid
graph TB
    A[分类管理] --> B[分类定义]
    A --> C[分类验证]
    A --> D[分类查询]
    
    B --> E[DocumentCategory]
    E --> F[CategoryCode]
    E --> G[CategoryDocument]
    
    C --> H{有效性检查}
    H -->|有效| I[接受分类]
    H -->|无效| J[返回错误]
    
    D --> K[过滤条件]
    K --> L[Repository查询]
    L --> M[数据库查询]
    M --> N[返回文档列表]
```

### 技术实现细节

#### 1. 分类定义

- **枚举常量**：使用常量定义分类类型
- **类型安全**：通过类型约束提高代码安全性
- **易于扩展**：新增分类只需添加新的常量
- **文档说明**：清晰的注释说明分类用途

#### 2. 分类验证

- **严格验证**：只接受预定义的分类
- **集中管理**：统一的验证逻辑
- **错误处理**：详细的错误信息
- **日志记录**：记录验证失败的情况

#### 3. 分类查询

- **索引支持**：在category字段上建立索引
- **过滤灵活**：支持与其他条件组合过滤
- **性能优化**：使用索引加速查询
- **结果缓存**：常用查询结果缓存

#### 4. 分类统计

- **文档计数**：统计每个分类的文档数量
- **使用分析**：分析分类的使用情况
- **趋势分析**：跟踪分类使用趋势
- **报表生成**：生成分类统计报表

### 扩展性考虑

1. **多级分类**：可以扩展为树形结构的分类
2. **自定义分类**：支持用户自定义分类
3. **分类映射**：支持分类的别名和映射
4. **分类权限**：可以基于分类设置访问权限

## feature-backup-restore (备份恢复功能)

### 设计理念

备份恢复功能提供了完整的数据备份和恢复机制，支持数据库备份、存储备份和完整备份。通过定时备份和手动备份相结合的方式，确保数据安全。恢复功能支持从备份文件或目录恢复数据，确保系统在故障时能够快速恢复。

### 实现深度剖析

#### 备份服务接口

[`BackupService`](internal/service/backup_service.go:12) 定义了备份服务的接口：

```go
type BackupService interface {
    BackupDatabase(ctx context.Context) (string, error)
    BackupStorage(ctx context.Context) (string, error)
    CreateFullBackup(ctx context.Context) (string, error)
    RestoreDatabase(ctx context.Context, backupFile string) error
    RestoreStorage(ctx context.Context, backupDir string) error
    GetBackupList(ctx context.Context) ([]BackupInfo, error)
    DeleteBackup(ctx context.Context, backupID string) error
}
```

**服务功能**：
- **数据库备份**：备份PostgreSQL数据库
- **存储备份**：备份文档存储目录
- **完整备份**：同时备份数据库和存储
- **数据恢复**：从备份恢复数据
- **备份管理**：列出和删除备份

#### 数据库备份

[`BackupService.BackupDatabase()`](internal/service/backup_service.go:58) 实现数据库备份：

```go
func (s *BackupServiceImpl) BackupDatabase(ctx context.Context) (string, error) {
    // 1. 生成带时间戳的备份文件名
    timestamp := time.Now().Format("20060102_150405")
    backupFile := filepath.Join(s.backupDir, fmt.Sprintf("database_%s.sql", timestamp))
    
    // 2. 执行数据库备份
    if err := s.db.DumpDatabase(ctx, backupFile); err != nil {
        return "", fmt.Errorf("failed to backup database: %v", err)
    }
    
    // 3. 验证备份文件
    if _, err := os.Stat(backupFile); err != nil {
        return "", fmt.Errorf("failed to verify backup file: %v", err)
    }
    
    return backupFile, nil
}
```

**备份流程**：
- **时间戳命名**：使用时间戳生成唯一的备份文件名
- **SQL转储**：使用pg_dump生成SQL转储文件
- **文件验证**：验证备份文件是否创建成功

#### 完整备份

[`BackupService.CreateFullBackup()`](internal/service/backup_service.go:88) 实现完整备份：

```go
func (s *BackupServiceImpl) CreateFullBackup(ctx context.Context) (string, error) {
    // 1. 创建备份目录
    timestamp := time.Now().Format("20060102_150405")
    fullBackupDir := filepath.Join(s.backupDir, fmt.Sprintf("full_%s", timestamp))
    
    if err := os.MkdirAll(fullBackupDir, 0755); err != nil {
        return "", fmt.Errorf("failed to create full backup directory: %v", err)
    }
    
    // 2. 备份数据库
    dbBackupFile := filepath.Join(fullBackupDir, "database.sql")
    if err := s.db.DumpDatabase(ctx, dbBackupFile); err != nil {
        return "", fmt.Errorf("failed to backup database in full backup: %v", err)
    }
    
    // 3. 创建存储备份信息
    storageBackupFile := filepath.Join(fullBackupDir, "storage_backup_info.txt")
    infoContent := fmt.Sprintf("Backup created at: %s\nStorage type: %s\n", 
        time.Now().Format(time.RFC3339), "local")
    if err := os.WriteFile(storageBackupFile, []byte(infoContent), 0644); err != nil {
        return "", fmt.Errorf("failed to create storage backup info: %v", err)
    }
    
    return fullBackupDir, nil
}
```

**完整备份**：
- **目录创建**：创建独立的备份目录
- **数据库备份**：备份到`database.sql`文件
- **存储信息**：记录存储备份的元数据

#### 数据库恢复

[`BackupService.RestoreDatabase()`](internal/service/backup_service.go:113) 实现数据库恢复：

```go
func (s *BackupServiceImpl) RestoreDatabase(ctx context.Context, backupFile string) error {
    // 1. 验证备份文件存在
    if _, err := os.Stat(backupFile); os.IsNotExist(err) {
        return fmt.Errorf("backup file does not exist: %s", backupFile)
    }
    
    // 2. 执行数据库恢复
    if err := s.db.RestoreDatabase(ctx, backupFile); err != nil {
        return fmt.Errorf("failed to restore database: %v", err)
    }
    
    return nil
}
```

**恢复流程**：
- **文件验证**：验证备份文件是否存在
- **数据恢复**：使用psql或pg_restore恢复数据
- **错误处理**：详细的错误信息

### 备份恢复流程

```mermaid
sequenceDiagram
    participant Admin
    participant BackupService
    participant DatabaseBackup
    participant PostgreSQL
    participant Storage
    participant FileSystem
    
    Admin->>BackupService: BackupDatabase()
    BackupService->>BackupService: 生成时间戳文件名
    BackupService->>DatabaseBackup: DumpDatabase(backupFile)
    DatabaseBackup->>PostgreSQL: pg_dump
    PostgreSQL-->>DatabaseBackup: SQL数据
    DatabaseBackup->>FileSystem: 写入SQL文件
    FileSystem-->>BackupService: 备份文件路径
    BackupService->>BackupService: 验证文件
    BackupService-->>Admin: 备份完成
    
    Admin->>BackupService: CreateFullBackup()
    BackupService->>FileSystem: 创建备份目录
    BackupService->>DatabaseBackup: DumpDatabase()
    DatabaseBackup-->>BackupService: 数据库备份
    BackupService->>FileSystem: 创建存储备份信息
    BackupService-->>Admin: 完整备份完成
    
    Admin->>BackupService: RestoreDatabase(backupFile)
    BackupService->>FileSystem: 验证文件存在
    FileSystem-->>BackupService: 文件存在
    BackupService->>DatabaseBackup: RestoreDatabase()
    DatabaseBackup->>PostgreSQL: psql < backup.sql
    PostgreSQL-->>DatabaseBackup: 恢复完成
    BackupService-->>Admin: 恢复完成
```

### 技术实现细节

#### 1. 备份触发机制

- **手动触发**：通过API手动触发备份
- **定时任务**：使用cron定时执行备份
- **事件触发**：关键操作后自动备份
- **策略配置**：可配置备份策略

#### 2. 备份压缩

- **文件压缩**：使用gzip压缩备份文件
- **压缩级别**：可配置压缩级别
- **加密存储**：支持备份文件加密
- **分卷备份**：大文件支持分卷备份

#### 3. 加密存储

- **AES加密**：使用AES-256加密备份文件
- **密钥管理**：安全的密钥存储机制
- **访问控制**：严格的备份文件访问控制
- **密钥轮换**：定期轮换加密密钥

#### 4. 数据一致性

- **一致性备份**：使用PostgreSQL的一致性备份
- **事务处理**：备份期间的事务处理
- **验证机制**：备份后验证数据完整性
- **测试恢复**：定期测试备份恢复

### 性能优化

1. **增量备份**：支持增量备份减少备份时间
2. **并行处理**：多个备份任务并行执行
3. **压缩优化**：使用高效的压缩算法
4. **网络优化**：远程备份使用高效传输协议

### 安全性考虑

1. **访问控制**：严格限制备份操作权限
2. **数据加密**：备份文件加密存储
3. **安全传输**：安全传输备份文件
4. **审计日志**：记录所有备份恢复操作
5. **备份验证**：定期验证备份完整性

## 总结

本文档深入分析了LAST-doc系统的9个核心功能实现，包括：

1. **文档上传功能**：实现了完整的HTTP请求处理、参数验证、文件存储、版本管理和异步解析流程
2. **文档解析功能**：采用多解析器架构，支持PDF、DOCX等多种格式，通过gRPC实现跨语言服务
3. **语义检索功能**：结合关键词搜索和向量相似度搜索，使用OpenAI Embedding和pgvector实现高效的语义检索
4. **用户认证功能**：采用JWT无状态认证和bcrypt密码加密，提供安全的用户身份验证和授权管理
5. **API密钥管理功能**：提供程序化访问机制，支持API密钥的生成、验证和失效管理
6. **文档版本管理功能**：实现完整的版本控制机制，支持多版本文档的上传、存储和查询
7. **标签系统功能**：使用PostgreSQL数组类型实现灵活的标签管理，支持高效的标签查询和统计
8. **分类管理功能**：提供层次化分类组织方式，通过枚举类型实现类型安全的分类管理
9. **备份恢复功能**：提供完整的数据备份和恢复机制，支持数据库备份、存储备份和完整备份

每个功能都采用了先进的技术实现和最佳实践，确保了系统的安全性、性能和可扩展性。通过详细的技术分析，开发者可以深入理解系统的工作原理，为后续的维护和扩展提供有力支持。