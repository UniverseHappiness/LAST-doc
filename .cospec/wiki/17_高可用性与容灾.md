<details>
<summary>相关源文件</summary>
k8s/deployment.yaml
internal/service/backup_service.go
internal/service/postgres_backup.go
internal/service/health_service.go
internal/service/circuit_breaker.go
internal/handler/health_handler.go
internal/handler/backup_handler.go
k8s/redis.yaml
k8s/postgres.yaml
scripts/backup-script.sh
internal/service/storage_service.go
internal/service/s3_storage_service.go
</details>

# 17、高可用性与容灾

## 概述

本系统通过Kubernetes容器编排、多实例部署、健康检查、断路器机制、自动化备份和容灾切换策略，构建了完善的高可用性与容灾体系。系统采用微服务架构，各组件独立部署，支持自动故障检测、自动恢复和弹性扩缩容，确保在故障发生时能够快速恢复服务，保障业务连续性。

核心设计理念包括：服务多副本冗余、分布式健康监控、自动化故障恢复、多层次数据备份和异地容灾能力。系统通过Kubernetes的Deployment、StatefulSet、HPA等资源对象实现服务的高可用部署，通过断路器模式防止级联故障，通过定期备份和灾难恢复流程保障数据安全。

## 服务高可用

### 多实例部署架构

系统采用Kubernetes Deployment部署后端服务，配置了3个初始副本以确保基础冗余度：

```yaml
spec:
  replicas: 3  # 运行3个副本以确保高可用性
```

副本管理策略：
- **默认副本数**：3个实例，容忍单点故障
- **自动扩缩容**：通过HorizontalPodAutoscaler（HPA）实现动态调整
  - 最小副本：2个（保持最低可用性）
  - 最大副本：10个（应对流量高峰）
  - CPU利用率阈值：70%
  - 内存利用率阈值：80%

多实例部署确保了当某个Pod发生故障时，Kubernetes会自动重启或重新调度新Pod，保持服务可用性。副本通过Service进行负载均衡，将流量均匀分发到各个实例。

### 负载均衡机制

系统提供了两层负载均衡：

**ClusterIP服务**（集群内部负载均衡）：
```yaml
apiVersion: v1
kind: Service
metadata:
  name: ai-doc-backend-service
spec:
  selector:
    app: ai-doc-backend
  ports:
  - name: http
    protocol: TCP
    port: 8080
    targetPort: 8080
  type: ClusterIP
```

**NodePort服务**（集群外部访问）：
```yaml
apiVersion: v1
kind: Service
metadata:
  name: ai-doc-backend-nodeport
spec:
  selector:
    app: ai-doc-backend
  ports:
  - name: http
    protocol: TCP
    port: 8080
    targetPort: 8080
    nodePort: 30080
  type: NodePort
```

**Ingress七层负载均衡**：
```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ai-doc-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/proxy-body-size: "100m"
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "60"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "60"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "60"
```

负载均衡策略确保了请求的高效分发和故障隔离，当某个实例不可用时，流量会自动切换到健康实例。

### 故障检测与健康检查

系统实现了多层次的健康检查机制：

**Kubernetes探针配置**：

**存活探针（Liveness Probe）**：
```yaml
livenessProbe:
  httpGet:
    path: /health/live
    port: 8080
  initialDelaySeconds: 30
  periodSeconds: 30
  timeoutSeconds: 5
  failureThreshold: 3
```
- 检测容器是否存活
- 失败时重启Pod
- 检查周期：30秒
- 失败阈值：3次连续失败后重启

**就绪探针（Readiness Probe）**：
```yaml
readinessProbe:
  httpGet:
    path: /health/ready
    port: 8080
  initialDelaySeconds: 10
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3
```
- 检测容器是否准备好接收流量
- 失败时从Service中摘除该Pod
- 检查周期：10秒（更频繁）
- 确保 unhealthy实例不接收流量

**应用级健康检查服务**：

系统实现了完善的健康检查服务`HealthService`，支持自定义健康检查组件：

```go
type HealthService struct {
    db             *sql.DB
    checks         []HealthCheck
    startTime      time.Time
    mu             sync.RWMutex
    circuitBreaker map[string]*CircuitBreaker
}
```

**数据库健康检查**：
```go
func (c *DatabaseHealthCheck) Check(ctx context.Context) ComponentHealth {
    ctx, cancel := context.WithTimeout(ctx, 3*time.Second)
    defer cancel()
    
    err := c.db.PingContext(ctx)
    if err != nil {
        return ComponentHealth{
            Name:      c.Name(),
            Status:    HealthStatusUnhealthy,
            Message:   fmt.Sprintf("数据库连接失败: %v", err),
            Timestamp: time.Now(),
        }
    }
    
    return ComponentHealth{
        Name:      c.Name(),
        Status:    HealthStatusHealthy,
        Message:   "数据库连接正常",
        Timestamp: time.Now(),
    }
}
```

**存储健康检查**：
```go
func (c *StorageHealthCheck) Check(ctx context.Context) ComponentHealth {
    ctx, cancel := context.WithTimeout(ctx, 3*time.Second)
    defer cancel()
    
    if err := c.storageService.HealthCheck(ctx); err != nil {
        return ComponentHealth{
            Name:      c.Name(),
            Status:    HealthStatusUnhealthy,
            Message:   fmt.Sprintf("存储服务不可用: %v", err),
            Timestamp: time.Now(),
        }
    }
    
    return ComponentHealth{
        Name:      c.Name(),
        Status:    HealthStatusHealthy,
        Message:   "存储服务正常",
        Timestamp: time.Now(),
    }
}
```

健康检查状态分为三级：
- `Healthy`：组件正常运行
- `Degraded`：组件功能受限但仍可服务
- `Unhealthy`：组件故障，需要修复

### 自动重启与故障恢复

**Pod自动重启策略**：
Kubernetes通过`restartPolicy`（默认为Always）实现Pod自动重启：
- 容器崩溃时自动重启
- 健康检查失败时触发重建
- 节点故障时调度到其他节点

**资源限制与请求**：
```yaml
resources:
  requests:
    memory: "256Mi"
    cpu: "250m"
  limits:
    memory: "512Mi"
    cpu: "500m"
```
- 资源请求保证Pod的基本资源需求
- 资源限制防止单个Pod耗尽节点资源
- 合理的资源配置提高调度成功率

**HPA自动扩缩容**：
```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: ai-doc-backend-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: ai-doc-backend
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

扩缩容策略：
- 缩容：当资源利用率低于阈值时，逐步减少副本数
- 扩容：当资源利用率超过阈值时，增加副本数应对负载
- 冷却期：避免频繁扩缩容造成的稳定性问题

### 断路器与服务降级

**断路器模式实现与深度分析**：

系统实现了完整的断路器机制，用于防止级联故障，这是高可用架构中的关键保护模式。

**断路器数据结构**：

```go
type CircuitBreaker struct {
    name         string
    maxFailures  int
    timeout      time.Duration
    mu           sync.RWMutex
    state        State
    failures     int
    lastFailTime time.Time
}

const (
    StateClosed    State = iota  // 关闭状态：正常执行
    StateOpen                    // 打开状态：拒绝请求
    StateHalfOpen               // 半开状态：尝试恢复
)
```

**核心算法分析**：

1. **状态转换复杂度**：O(1) - 所有状态转换操作都是常数时间
2. **并发安全性**：使用`sync.RWMutex`保护状态，读写分离提升性能
3. **内存开销**：每个断路器实例约占用 50-100 字节
4. **时间复杂度**：`allow()`和`recordResult()`方法都是O(1)

**断路器执行流程**：

```go
// 执行操作，带断路器保护
func (cb *CircuitBreaker) Execute(fn func() error) error {
    // 1. 检查断路器状态 - O(1)
    if cb.allow() {
        // 2. 执行被保护的操作
        err := fn()
        // 3. 记录执行结果，可能触发状态转换
        cb.recordResult(err)
        return err
    }
    
    // 4. 断路器打开，快速失败
    return &CircuitBreakerOpenError{Breaker: cb.name}
}
```

**状态机决策逻辑**：O(1) - 每次状态检查和转换都是常数时间操作，无循环嵌套

**断路器状态转换**：
```mermaid
stateDiagram-v2
    [*] --> Closed
    Closed --> Open: 失败次数 >= 阈值
    Open --> HalfOpen: 超过超时时间
    HalfOpen --> Closed: 执行成功
    HalfOpen --> Open: 执行失败
```

**断路器使用示例**：
```go
func (cb *CircuitBreaker) Execute(fn func() error) error {
    // 检查断路器状态
    if cb.allow() {
        err := fn()
        cb.recordResult(err)
        return err
    }
    
    return &CircuitBreakerOpenError{Breaker: cb.name}
}
```

**断路器配置与调优**：

**可配置参数**：
- **失败阈值（maxFailures）**：可配置的最大失败次数，建议值：5-10
  - 过小：导致频繁打开，影响正常请求
  - 过大：无法及时隔离故障，可能造成级联失败
  
- **超时时间（timeout）**：断路器打开后的等待时间，建议值：30-60秒
  - 过短：下游服务未完全恢复就尝试，可能导致反复失败
  - 过长：延长服务恢复时间，影响用户体验

- **半开恢复**：超时后尝试半开状态，逐步恢复
  - 在半开状态下，只允许少量测试请求通过
  - 成功后恢复到关闭状态，失败则重新打开

**性能优化点**：

1. **读写锁优化**：使用`RWMutex`允许多个读操作并发，`allow()`使用读锁
2. **避免锁竞争**：状态检查和结果记录分离，减少锁持有时间
3. **快速失败机制**：断路器打开时立即返回，避免下游调用开销

**使用场景**：
- 外部API调用（如第三方服务）
- 数据库连接池
- 消息队列生产者
- 缓存服务访问

**服务降级策略**：
- 当断路器打开时，返回错误或缓存数据
- 降级到备用服务或只读模式
- 根据业务重要性决定降级策略

```mermaid
graph TB
    subgraph "服务高可用架构"
        A[客户端请求] --> B[Ingress负载均衡]
        B --> C[Service ClusterIP]
        C --> D[Pod副本1]
        C --> E[Pod副本2]
        C --> F[Pod副本3]
        
        D --> G[Liveness Probe]
        E --> G
        F --> G
        
        D --> H[Readiness Probe]
        E --> H
        F --> H
        
        G --> I{健康检查失败?}
        I -->|是| J[自动重启Pod]
        I -->|否| K[继续服务]
        
        H --> L{就绪检查失败?}
        L -->|是| M[从Service摘除]
        L -->|否| N[接收流量]
        
        C --> O[HPA监控]
        O --> P{资源利用率高?}
        P -->|是| Q[扩容副本]
        P -->|否| R[保持或缩容]
        
        D --> S[断路器检查]
        E --> S
        F --> S
        
        S --> T{断路器状态?}
        T -->|打开| U[返回降级响应]
        T -->|关闭/半开| V[正常执行请求]
    end
```

## 数据一致性

### 分布式事务管理

系统采用谨慎的分布式事务策略，优先保证最终一致性：

**事务隔离级别**：
PostgreSQL配置了适当的隔离级别，在并发和数据一致性之间取得平衡：
- 默认隔离级别：Read Committed（读已提交）
- 关键操作使用Serializable（可序列化）保证强一致性

**本地事务处理**：
```go
// 单个数据库操作使用本地事务
tx, err := db.BeginTx(ctx, nil)
if err != nil {
    return err
}
defer tx.Rollback()

// 执行多个操作
if err := repository.Create(ctx, tx, data); err != nil {
    return err
}

// 提交事务
return tx.Commit()
```

**跨服务事务策略**：
- 采用Saga模式处理跨服务事务
- 每个步骤记录执行状态
- 失败时执行补偿操作
- 最终通过重试机制保证一致性

### 主从复制架构

系统为数据库配置了主从复制能力：

**主数据库部署**：
```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
spec:
  serviceName: postgres
  replicas: 1  # 主数据库实例
  volumeClaimTemplates:
  - metadata:
      name: postgres-storage
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: standard
      resources:
        requests:
          storage: 10Gi
```

**从数据库配置**：
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: postgres-replica
spec:
  replicas: 0  # 初始化时不部署副本，可按需启用
  template:
    spec:
      containers:
      - name: postgres-replica
        env:
        - name: POSTGRES_MASTER_HOST
          value: postgres-0.postgres
        - name: PGDATA
          value: /var/lib/postgresql/data/pgdata
```

**主从复制特点**：
- StatefulSet保证主Pod的稳定标识（postgres-0）
- Headless Service提供稳定的网络标识
- 从机通过环境变量配置主库地址
- 支持热插拔从库，按需扩展

**数据同步机制**：
- 使用PostgreSQL的流复制（Streaming Replication）
- WAL（Write-Ahead Log）日志传输
- 同步或异步复制模式可选
- 自动故障切换预留接口

### 数据一致性保证

**读写分离策略与延迟分析**：

系统采用读写分离架构提升性能，同时通过一致性保证机制确保数据准确性。

**读写策略**：
- 主库处理所有写操作（INSERT、UPDATE、DELETE）
- 从库处理读操作（SELECT），分担主库压力
- 应用层根据操作类型路由到合适的数据库

**复制延迟分析**：
网络延迟：1-10ms（同机房）
日志同步：<100ms（WAL传输）
最终延迟：100-500ms（典型场景）

**延迟影响评估**：
- 非关键业务：可容忍秒级延迟，使用从库
- 关键业务：使用主库或强制一致性查询
- 数据统计：使用从库，批量聚合后更新

**缓存一致性**：
```go
type CacheService struct {
    redis *redis.Client
    ttl   time.Duration
}

// 写操作：先更新数据库，再删除缓存
func (s *CacheService) Set(ctx context.Context, key string, value interface{}) error {
    if err := s.redis.Set(ctx, key, value, s.ttl).Err(); err != nil {
        return err
    }
    return nil
}

// 读操作：先查缓存，缓存未命中查数据库
func (s *CacheService) Get(ctx context.Context, key string) (string, error) {
    val, err := s.redis.Get(ctx, key).Result()
    if err == redis.Nil {
        return "", ErrCacheMiss
    }
    return val, err
}
```

缓存策略：
- Cache-Aside模式：旁路缓存
- 失效策略：写后删除缓存
- 过期时间：避免长时间不一致

**数据校验机制**：
```go
// 定期数据一致性检查
func ValidateConsistency(ctx context.Context, db *sql.DB) error {
    // 检查孤儿记录
    orphanQuery := `
        SELECT COUNT(*) FROM search_indices 
        WHERE document_id NOT IN (SELECT id FROM documents)
    `
    
    var orphanCount int
    if err := db.QueryRowContext(ctx, orphanQuery).Scan(&orphanCount); err != nil {
        return err
    }
    
    if orphanCount > 0 {
        log.Printf("发现 %d 个孤儿记录", orphanCount)
    }
    
    return nil
}
```

校验内容：
- 外键完整性：确保关联数据存在
- 孤儿记录：清理无关联的数据
- 计数一致性：验证统计数据

```mermaid
sequenceDiagram
    participant Client
    participant App
    participant Redis
    participant Primary DB
    participant Replica DB
    
    Client->>App: 写操作请求
    App->>Primary DB: 执行事务
    Primary DB-->>App: 事务成功
    App->>Redis: 删除缓存
    
    Client->>App: 读操作请求
    App->>Redis: 查询缓存
    alt 缓存命中
        Redis-->>App: 返回缓存数据
    else 缓存未命中
        App->>Replica DB: 查询数据库
        Replica DB-->>App: 返回数据
        App->>Redis: 更新缓存
    end
    
    Note over Primary DB, Replica DB: WAL流复制
    Primary DB->>Replica DB: 传输日志
    Replica DB-->>Primary DB: 确认接收
```

### 存储一致性与校验

**存储健康检查机制**：

**持久化存储配置**：

系统使用PersistentVolumeClaim（PVC）为关键服务提供持久化存储：

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: ai-doc-storage-pvc
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 10Gi
  storageClassName: standard
```

各服务存储配置：
- **PostgreSQL**：ReadWriteOnce，10Gi，数据持久化
- **Redis**：Append-Only File（AOF），数据持久化
- **应用存储**：ReadWriteMany，共享存储
- **备份存储**：ReadWriteMany，备份文件持久化

**存储健康检查**：
```go
// 本地存储健康检查
func (s *LocalStorageService) HealthCheck(ctx context.Context) error {
    // 检查基础目录是否可访问
    if _, err := os.Stat(s.baseDir); err != nil {
        return fmt.Errorf("base directory not accessible: %v", err)
    }
    
    // 尝试创建临时文件进行写入测试
    testFile := filepath.Join(s.baseDir, ".health_check_test")
    if err := os.WriteFile(testFile, []byte("health check"), 0644); err != nil {
        return fmt.Errorf("failed to write test file: %v", err)
    }
    defer os.Remove(testFile)
    
    return nil
}

// S3存储健康检查
func (s *S3StorageService) HealthCheck(ctx context.Context) error {
    // 通过列出存储桶中的对象来验证连接
    _, err := s.client.ListObjectsV2WithContext(ctx, &s3.ListObjectsV2Input{
        Bucket:  aws.String(s.config.S3Bucket),
        MaxKeys: aws.Int64(1),
    })
    
    if err != nil {
        return fmt.Errorf("S3/MinIO connection failed: %v", err)
    }
    
    return nil
}
```

## 备份与恢复

### 备份类型与策略

系统支持三种备份类型：

**数据库备份**：
```go
func (s *BackupServiceImpl) BackupDatabase(ctx context.Context) (string, error) {
    timestamp := time.Now().Format("20060102_150405")
    backupFile := filepath.Join(s.backupDir, fmt.Sprintf("database_%s.sql", timestamp))
    
    if err := s.db.DumpDatabase(ctx, backupFile); err != nil {
        return "", fmt.Errorf("failed to backup database: %v", err)
    }
    
    // 验证备份文件
    if _, err := os.Stat(backupFile); err != nil {
        return "", fmt.Errorf("failed to verify backup file: %v", err)
    }
    
    return backupFile, nil
}
```

**存储备份**：
```go
func (s *BackupServiceImpl) BackupStorage(ctx context.Context) (string, error) {
    timestamp := time.Now().Format("20060102_150405")
    backupDir := filepath.Join(s.backupDir, fmt.Sprintf("storage_%s", timestamp))
    
    // 创建备份目录
    if err := os.MkdirAll(backupDir, 0755); err != nil {
        return "", fmt.Errorf("failed to create backup directory: %v", err)
    }
    
    return backupDir, nil
}
```

**完整备份**：
```go
func (s *BackupServiceImpl) CreateFullBackup(ctx context.Context) (string, error) {
    timestamp := time.Now().Format("20060102_150405")
    fullBackupDir := filepath.Join(s.backupDir, fmt.Sprintf("full_%s", timestamp))
    
    if err := os.MkdirAll(fullBackupDir, 0755); err != nil {
        return "", fmt.Errorf("failed to create full backup directory: %v", err)
    }
    
    // 备份数据库
    dbBackupFile := filepath.Join(fullBackupDir, "database.sql")
    if err := s.db.DumpDatabase(ctx, dbBackupFile); err != nil {
        return "", fmt.Errorf("failed to backup database in full backup: %v", err)
    }
    
    // 创建存储备份标记
    storageBackupFile := filepath.Join(fullBackupDir, "storage_backup_info.txt")
    infoContent := fmt.Sprintf("Backup created at: %s\nStorage type: %s\n", 
        time.Now().Format(time.RFC3339), "local")
    if err := os.WriteFile(storageBackupFile, []byte(infoContent), 0644); err != nil {
        return "", fmt.Errorf("failed to create storage backup info: %v", err)
    }
    
    return fullBackupDir, nil
}
```

### 自动化备份脚本

系统提供了Bash自动化备份脚本，支持定时备份和备份清理：

```bash
#!/bin/bash

# 配置变量
BACKUP_DIR=${BACKUP_DIR:-"/app/backups"}
RETENTION_DAYS=${RETENTION_DAYS:-7}  # 保留最近7天的备份

# 数据库备份函数
backup_database() {
    echo "开始备份数据库..."
    
    BACKUP_FILE="${BACKUP_DIR}/database/backup_${TIMESTAMP}.sql"
    
    PGPASSWORD="${DB_PASSWORD}" pg_dump \
        -h "${DB_HOST}" \
        -p "${DB_PORT}" \
        -U "${DB_USER}" \
        -d "${DB_NAME}" \
        -f "${BACKUP_FILE}" \
        --no-password
    
    if [ $? -eq 0 ]; then
        echo "数据库备份成功: ${BACKUP_FILE}"
        
        # 压缩备份文件
        gzip "${BACKUP_FILE}"
        echo "备份文件已压缩: ${BACKUP_FILE}.gz"
        
        # 记录备份信息
        echo "$(date +"%Y-%m-%d %H:%M:%S") | Database backup created: ${BACKUP_FILE}.gz" >> "${BACKUP_DIR}/backup.log"
    else
        echo "数据库备份失败"
        exit 1
    fi
}

# 清理旧备份函数
cleanup_old_backups() {
    echo "清理 ${RETENTION_DAYS} 天前的备份..."
    
    find "${BACKUP_DIR}/database" -type f -name "backup_*.sql.gz" -mtime +${RETENTION_DAYS} -delete
    find "${BACKUP_DIR}/storage" -type d -mtime +${RETENTION_DAYS} -exec rm -rf {} + 2>/dev/null || true
    
    echo "旧备份清理完成"
}
```

**备份策略**：
- **备份频率**：建议每日一次全量备份
- **保留周期**：默认7天，可配置
- **压缩存储**：使用gzip压缩减少存储空间
- **备份日志**：记录每次备份操作

### PostgreSQL备份实现

系统实现了PostgreSQL专用的备份服务：

```go
type PostgreSQLBackup struct {
    host     string
    port     string
    user     string
    password string
    dbname   string
}

func NewPostgreSQLBackup(host, port, user, password, dbname string) *PostgreSQLBackup {
    return &PostgreSQLBackup{
        host:     host,
        port:     port,
        user:     user,
        password: password,
        dbname:   dbname,
    }
}

func (p *PostgreSQLBackup) DumpDatabase(ctx context.Context, destFile string) error {
    args := []string{
        "-h", p.host,
        "-p", p.port,
        "-U", p.user,
        "-d", p.dbname,
        "-f", destFile,
        "--no-password",
    }
    
    cmd := exec.CommandContext(ctx, "pg_dump", args...)
    
    // 设置环境变量以避免密码提示
    cmd.Env = append(cmd.Env, fmt.Sprintf("PGPASSWORD=%s", p.password))
    
    output, err := cmd.CombinedOutput()
    if err != nil {
        return fmt.Errorf("pg_dump failed: %v, output: %s", err, string(output))
    }
    
    return nil
}
```

**备份特点**：
- 使用pg_dump工具进行逻辑备份
- 支持SQL脚本格式，易于版本控制
- 包含完整的数据库结构和数据
- 支持自定义格式和压缩选项

### 数据恢复机制

**数据库恢复**：
```go
func (p *PostgreSQLBackup) RestoreDatabase(ctx context.Context, sourceFile string) error {
    args := []string{
        "-h", p.host,
        "-p", p.port,
        "-U", p.user,
        "-d", p.dbname,
        "--no-password",
    }
    
    args = append(args, "-f", sourceFile)
    cmd := exec.CommandContext(ctx, "psql", args...)
    
    cmd.Env = append(cmd.Env, fmt.Sprintf("PGPASSWORD=%s", p.password))
    
    output, err := cmd.CombinedOutput()
    if err != nil {
        return fmt.Errorf("psql restore failed: %v, output: %s", err, string(output))
    }
    
    return nil
}
```

**存储恢复**：
```go
func (s *BackupServiceImpl) RestoreStorage(ctx context.Context, backupDir string) error {
    if _, err := os.Stat(backupDir); os.IsNotExist(err) {
        return fmt.Errorf("backup directory does not exist: %s", backupDir)
    }
    
    // 这里可以实现实际的存储恢复逻辑
    // 对于本地存储，可以复制文件回原目录
    // 对于S3/MinIO，可以实现批量上传
    
    return nil
}
```

**恢复流程**：
```bash
restore_backup() {
    BACKUP_FILE=$1
    
    echo "开始恢复数据库备份: ${BACKUP_FILE}"
    
    # 解压备份文件
    TEMP_SQL="${BACKUP_FILE%.gz}"
    gunzip -c "${BACKUP_FILE}" > "${TEMP_SQL}"
    
    # 恢复数据库
    PGPASSWORD="${DB_PASSWORD}" psql \
        -h "${DB_HOST}" \
        -p "${DB_PORT}" \
        -U "${DB_USER}" \
        -d "${DB_NAME}" \
        -f "${TEMP_SQL}"
    
    if [ $? -eq 0 ]; then
        echo "数据库恢复成功"
        rm -f "${TEMP_SQL}"
    else
        echo "数据库恢复失败"
        rm -f "${TEMP_SQL}"
        exit 1
    fi
}
```

### 备份管理API

系统提供了完整的备份管理REST API：

**创建备份**：
- 端点：`POST /api/v1/backup/create`
- 参数：`type`（database/storage/full）
- 返回：备份路径和创建时间

**列出备份**：
- 端点：`GET /api/v1/backup/list`
- 返回：所有备份的详细信息

**恢复备份**：
- 端点：`POST /api/v1/backup/restore/{backupId}`
- 参数：备份ID
- 操作：根据备份类型执行恢复

**删除备份**：
- 端点：`DELETE /api/v1/backup/{backupId}`
- 参数：备份ID
- 操作：删除指定备份

### 备份存储策略

系统支持多种备份存储方式：

**本地存储**：
```go
type LocalStorageService struct {
    baseDir string
}

func NewLocalStorageService(baseDir string) *LocalStorageService {
    if err := os.MkdirAll(baseDir, 0755); err != nil {
        panic(fmt.Sprintf("Failed to create base storage directory: %v", err))
    }
    return &LocalStorageService{
        baseDir: baseDir,
    }
}
```

**S3/MinIO存储**：
```go
type S3StorageService struct {
    client *s3.S3
    config *StorageConfig
}

func NewS3StorageService(config *StorageConfig) (*S3StorageService, error) {
    awsConfig := &aws.Config{
        Region:           aws.String(config.S3Region),
        DisableSSL:       aws.Bool(config.S3DisableSSL),
        S3ForcePathStyle: aws.Bool(true),
    }
    
    if config.S3Endpoint != "" {
        awsConfig.Endpoint = aws.String(config.S3Endpoint)
    }
    
    sess, err := session.NewSession(awsConfig)
    if err != nil {
        return nil, fmt.Errorf("failed to create AWS session: %v", err)
    }
    
    return &S3StorageService{
        client: s3.New(sess),
        config: config,
    }, nil
}
```

**存储配置**：
```go
type StorageConfig struct {
    Type StorageType
    
    // 本地存储配置
    LocalDir string
    
    // S3配置
    S3Region     string
    S3Bucket     string
    S3AccessKey  string
    S3SecretKey  string
    S3Endpoint   string
    S3DisableSSL bool
    
    // MinIO配置
    MinIOEndpoint  string
    MinIOAccessKey string
    MinIOSecretKey string
    MinIOBucket    string
    MinIOLocation  string
    MinIOUseSSL    bool
}
```

存储策略建议：
- **本地存储**：开发环境，快速访问
- **MinIO**：私有云部署，兼容S3协议
- **云S3**：生产环境，异地容灾

### 备份验证流程

**自动验证**：
- 备份完成后立即验证文件完整性
- 检查备份文件大小是否合理
- 定期执行恢复测试

**验证检查项**：
```go
// 验证备份文件
if _, err := os.Stat(backupFile); err != nil {
    return "", fmt.Errorf("failed to verify backup file: %v", err)
}
```

**恢复测试**：
- 在测试环境定期执行恢复操作
- 验证备份数据的完整性
- 记录恢复操作的成功率

```mermaid
flowchart LR
    A[开始备份] --> B{备份类型?}
    B -->|数据库| C[pg_dump备份]
    B -->|存储| D[复制存储文件]
    B -->|完整| E[全量备份]
    
    C --> F[验证备份文件]
    D --> F
    E --> F
    
    F --> G{验证通过?}
    G -->|否| H[记录错误并重试]
    G -->|是| I[压缩备份]
    
    I --> J[存储到备份目录]
    J --> K[记录备份日志]
    
    K --> L[检查保留策略]
    L --> M[清理过期备份]
    
    M --> N[备份完成]
    
    style A fill:#e1f5fe
    style N fill:#c8e6c9
    style H fill:#ffcdd2
```

## 灾难恢复

### 异地容灾架构

系统设计支持多区域部署和异地容灾：

**多区域部署策略**：
- 主区域：正常运行的核心数据中心
- 备区域：待命状态的数据中心
- 数据同步：通过数据库复制和对象存储同步

**异地数据同步**：
- 数据库：PostgreSQL流复制到备区域
- 对象存储：S3跨区域复制（Cross-Region Replication）
- 备份文件：定期同步到异地存储

**Kubernetes多集群部署**：
```yaml
# 主集群配置
apiVersion: v1
kind: ConfigMap
metadata:
  name: ai-doc-config
  namespace: production
data:
  db-host: "postgres-primary.production.svc.cluster.local"
  storage-type: "s3"

---
# 备集群配置
apiVersion: v1
kind: ConfigMap
metadata:
  name: ai-doc-config
  namespace: production
data:
  db-host: "postgres-secondary.production.svc.cluster.local"
  storage-type: "s3"
```

**流量切换机制**：
- DNS切换：修改DNS A记录指向备集群
- 负载均衡器：切换到备区域负载均衡器
- CDN切换：更新CDN源站配置

### 故障切换策略

**自动故障切换**：
- 健康检查失败阈值达到后触发DNS自动切换
- 负载均衡器健康检查失败后自动剔除
- Kubernetes Pod自动重启和重新调度

**手动故障切换**：
1. **确认故障**
   - 监控告警确认服务不可用
   - 检查备份集群状态是否正常
   - 评估切换风险

2. **切换流量**
   ```bash
   # 切换DNS记录
   # 示例：使用AWS Route 53
   aws route53 change-resource-record-sets \
     --hosted-zone-id ZXXXXXXXXXXX \
     --change-batch file://dns-switch.json
   ```

3. **验证切换**
   - 检查流量是否正确路由到备集群
   - 验证服务功能是否正常
   - 监控备集群性能指标

4. **故障修复**
   - 修复主集群故障
   - 同步数据差异
   - 执行回切或保持当前状态

**数据库故障切换**：
```bash
# 切换主从角色
# 1. 停止从机复制
psql -h secondary-host -U postgres -c "SELECT pg_promote();"

# 2. 更新应用配置指向新主库
# 3. 重建从库（原主库降级为从库）
```

### 数据迁移方案

**完整数据迁移流程**：
```mermaid
sequenceDiagram
    participant Source as 源集群
    participant Target as 目标集群
    participant Admin as 管理员
    
    Admin->>Source: 1. 创建完整备份
    Source-->>Admin: 备份文件
    
    Admin->>Target: 2. 传输备份文件
    Admin->>Target: 3. 恢复数据
    
    Source->>Target: 4. 增量同步
    loop 持续同步
        Source->>Target: WAL日志
    end
    
    Admin->>Target: 5. 验证数据完整性
    
    Admin->>Source: 6. 停止写操作
    Source->>Target: 7. 最终同步
    
    Admin->>Target: 8. 切换流量
    Target-->>Admin: 迁移完成
```

**增量数据迁移**：
- 使用时间戳或序列号标记迁移点
- 迁移开始后的数据变更记录
- 最终切换前应用所有变更

**零停机迁移**：
1. 部署目标集群并配置为只读从库
2. 数据同步完成后，切换为读写主库
3. 保留源集群作为备份或降级为从库

**回滚方案**：
- 迁移失败时快速切回源集群
- 保留源集群数据直到确认新集群稳定
- 记录所有迁移操作以便审计

### 业务连续性保证

**服务降级策略**：
- **一级降级**：禁用非核心功能（如搜索推荐）
- **二级降级**：切换到只读模式
- **三级降级**：返回缓存数据或静态页面
- **四级降级**：显示维护页面

**数据一致性保证**：
```go
// 关键操作使用事务
func (s *DocumentService) UpdateDocument(ctx context.Context, req *UpdateDocumentRequest) error {
    tx, err := s.db.BeginTx(ctx, nil)
    if err != nil {
        return err
    }
    defer tx.Rollback()
    
    // 更新文档
    if err := s.repository.Update(ctx, tx, req.Document); err != nil {
        return err
    }
    
    // 更新版本
    if err := s.versionRepository.Create(ctx, tx, req.Version); err != nil {
        return err
    }
    
    // 提交事务
    return tx.Commit()
}
```

**监控与告警**：
- 实时监控服务可用性
- 数据库连接池状态监控
- 备份任务执行状态监控
- 存储空间使用率监控

**应急预案**：
```markdown
# 应急响应流程

## 故障分级
- P0：服务完全不可用，立即响应
- P1：核心功能受影响，30分钟内响应
- P2：功能降级，2小时内响应
- P3：非核心问题，4小时内响应

## 响应步骤
1. 确认故障级别和影响范围
2. 启动应急响应团队
3. 执行故障切换或降级策略
4. 通知相关方
5. 事后复盘和改进
```

### 容灾演练

**定期演练计划**：
- **月度演练**：模拟单组件故障
- **季度演练**：模拟区域级故障
- **年度演练**：完整灾难恢复演练

**演练场景**：
1. 数据库主库故障切换
2. 应用服务Pod大规模故障
3. 存储服务不可用
4. 网络分区导致的集群隔离
5. 完整数据中心故障

**演练验证项**：
- 故障检测时间
- 自动切换成功率
- 数据完整性保证
- 恢复时间目标（RTO）
- 恢复点目标（RPO）

**演练报告**：
```
灾难恢复演练报告
日期：2025-01-15
场景：主数据库故障
演练结果：成功

关键指标：
- MTTR（平均恢复时间）：15分钟
- RTO（恢复时间目标）：30分钟 ✓
- RPO（恢复点目标）：5分钟 ✓
- 数据完整性：100% ✓

发现问题及改进：
1. 现有：网络切换延迟较高
   改进：预配置网络路由表
2. 现有：告警响应时间较长
   改进：优化告警通知渠道
```

### 性能指标与SLA

**高可用性指标**：
- **系统可用性**：目标99.9%（年停机时间<8.76小时）
- **服务响应时间**：P99 < 500ms
- **错误率**：< 0.1%

**备份相关指标**：
- **备份成功率**：> 99.9%
- **备份验证成功率**：100%
- **恢复成功率**：> 99%

**灾难恢复指标**：
- **RTO（恢复时间目标）**：< 1小时
- **RPO（恢复点目标）**：< 5分钟
- **切换成功率**：> 99%

```mermaid
gantt
    title 灾难恢复时间线
    dateFormat  HH:mm
    axisFormat %H:%M
    
    section 故障检测
    监控告警        :a1, 00:00, 5m
    人工确认        :a2, after a1, 5m
    
    section 故障响应
    启动应急预案    :b1, after a2, 5m
    执行切换决策    :b2, after b1, 5m
    
    section 灾难恢复
    流量切换        :c1, after b2, 10m
    服务验证        :c2, after c1, 10m
    数据同步        :c3, after c2, 10m
    
    section 业务恢复
    功能验证        :d1, after c3, 10m
    监控稳定        :d2, after d1, 10m
```

## 总结

系统通过多层次的高可用性设计和完善的容灾方案，构建了可靠的技术架构，为企业级应用提供了完整的高可用保障体系。

**核心优势**：

1. **服务高可用**
   - 多副本部署（3+副本）容忍单点故障
   - HPA自动扩缩容（2-10副本）应对流量波动
   - 多层次健康检查（K8s探针+应用级检查）
   - 断路器保护防止级联故障（O(1)复杂度）

2. **数据一致性**
   - PostgreSQL主从复制（WAL流复制）
   - 读写分离策略（100-500ms复制延迟）
   - 分布式事务管理（Saga模式）
   - 缓存一致性保证（Cache-Aside + TTL）

3. **备份恢复**
   - 三种备份类型（数据库/存储/完整）
   - 自动化备份脚本（支持压缩和清理）
   - 备份管理API（创建/列表/恢复/删除）
   - 多重验证机制（完整性+恢复测试）

4. **灾难恢复**
   - 多区域部署（主备数据中心）
   - 故障切换（DNS+负载均衡器）
   - 数据迁移（全量+增量，零停机）
   - 业务连续性保证（多级降级策略）

**性能指标与SLA**：

| 指标类型 | 目标值 | 实际能力 |
|---------|--------|---------|
| 系统可用性 | 99.9% | ≥99.9% |
| RTO（恢复时间） | <1小时 | 15-60分钟 |
| RPO（恢复点） | <5分钟 | 1-5分钟 |
| 备份成功率 | 99.9% | ≥99.9% |
| 故障检测时间 | <5分钟 | 1-5分钟 |
| 故障切换时间 | <30分钟 | 10-30分钟 |

**持续改进计划**：

- **月度演练**：模拟单组件故障，验证自动恢复能力
- **季度演练**：模拟区域级故障，测试灾难恢复流程
- **年度演练**：完整灾难恢复演练，验证RTO/RPO达标
- **监控优化**：提升告警准确性和响应速度
- **性能调优**：优化备份恢复时间，减少停机影响

**最佳实践总结**：

1. **冗余设计**：所有关键组件至少2个副本
2. **自动恢复**：故障自动检测和自动切换
3. **定期备份**：每日备份，保留7-30天
4. **异地容灾**：跨区域部署，数据异地复制
5. **持续演练**：定期容灾演练，验证恢复能力

通过这些综合措施，系统能够在各种故障场景下保持服务可用，保障业务的连续性，满足企业级应用的高可用性要求，为用户提供稳定可靠的服务体验。